{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53e73d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import block\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.modeling_outputs import BaseModelOutput, Seq2SeqLMOutput\n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from packaging import version\n",
    "\n",
    "from datasets import list_datasets, load_dataset, list_metrics, load_metric\n",
    "from datasets import Dataset\n",
    "\n",
    "import sacrebleu\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34ee1450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions from GP-VAE implementation\n",
    "\n",
    "# Specific to dataset.\n",
    "def construct_input_for_batch(tokenizer, batch, args):\n",
    "    \"\"\"\n",
    "    Function that takes a batch from a dataset and constructs the corresponding \n",
    "    input string.\n",
    "    \"\"\"\n",
    "    source, target = [], []\n",
    "    for inp, out in zip(batch['source'], batch['target']):\n",
    "        source.append(inp.strip())\n",
    "        target.append(out.strip())\n",
    "    if batch['id'][0] == 0:\n",
    "        print(source[0])\n",
    "        print(target[0])\n",
    "        print()\n",
    "    return source, target\n",
    "\n",
    "def make_batch_inputs(batch, tokenizer, args, device='cuda:0'):\n",
    "  \"\"\"\n",
    "  Function that takes a batch from a dataset and transforms it \n",
    "  \"\"\"\n",
    "  # Concatenate the concept names for each example in the batch.\n",
    "  input_lists, _ = construct_input_for_batch(tokenizer, batch, args)\n",
    "  # Use the model's tokenizer to create the batch input_ids.\n",
    "  batch_features = tokenizer(input_lists, padding=True, return_tensors='pt')\n",
    "  # Move all inputs to the device.\n",
    "  batch_features = dict([(k, v.to(device)) for k, v in batch_features.items()])\n",
    "  return batch_features\n",
    "\n",
    "def make_batch_data(batch, tokenizer, args, device='cuda:0'):\n",
    "  \"\"\"\n",
    "  Function that takes a batch from a dataset and transforms it \n",
    "  \"\"\"\n",
    "  # Concatenate the concept names for each example in the batch.\n",
    "  input_lists, label_list = construct_input_for_batch(tokenizer, batch, args)\n",
    "  # Use the model's tokenizer to create the batch input_ids.\n",
    "  batch_features = tokenizer(input_lists, padding=True, return_tensors='pt')\n",
    "  batch_labels = tokenizer(label_list, padding=True, return_tensors='pt')\n",
    "  # Move all inputs to the device.\n",
    "  batch_features = dict([(k, v.to(device)) for k, v in batch_features.items()])\n",
    "  batch_labels = dict([(k, v.to(device)) for k, v in batch_labels.items()])\n",
    "  return batch_features, batch_labels\n",
    "\n",
    "def batch_tokenize(dataset_batch, tokenizer, args):\n",
    "  \"\"\"\n",
    "  Reuse the function defined above to construct the batch (source, target) and \n",
    "  run them through the tokenizer.\n",
    "  \"\"\"\n",
    "  source, target = construct_input_for_batch(tokenizer, dataset_batch, args)\n",
    "  res = {\n",
    "          \"input_ids\": tokenizer(\n",
    "              source,\n",
    "              padding='max_length', \n",
    "              truncation=True,\n",
    "              max_length=args.encoder_max_length\n",
    "          )[\"input_ids\"],\n",
    "          \"labels\": tokenizer(\n",
    "              target,\n",
    "              padding='max_length', \n",
    "              truncation=True,\n",
    "              max_length=args.decoder_max_length\n",
    "          )[\"input_ids\"],\n",
    "  }\n",
    "  return res\n",
    "\n",
    "def batchify_data(df, tokenizer, args):\n",
    "  dataset = Dataset.from_pandas(df)\n",
    "  data_tokenized = dataset.map(\n",
    "    lambda batch: batch_tokenize(batch, tokenizer, args),\n",
    "    batched=True\n",
    "  )\n",
    "  return data_tokenized\n",
    "\n",
    "def compute_loss(batch, model, tokenizer, args):\n",
    "  batch_feature, batch_label = make_batch_data(batch, tokenizer, args)\n",
    "  with torch.no_grad():\n",
    "    outputs = model(input_ids=batch_feature['input_ids'],\n",
    "                    labels=batch_label['input_ids'])\n",
    "    eval_loss = outputs.loss.item()\n",
    "  return [eval_loss] \n",
    "\n",
    "def test_ppl(val_df, model, tokenizer, args):\n",
    "  loss_dict = Dataset.from_pandas(val_df).map(\n",
    "    lambda batch: {'loss': compute_loss(batch, model, tokenizer, args)},\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    "  )\n",
    "  \n",
    "  eval_loss = 0.\n",
    "  nb_eval_steps = 0\n",
    "  for item in list(loss_dict):\n",
    "      eval_loss += item['loss']\n",
    "      nb_eval_steps += 1\n",
    "  eval_loss = eval_loss / nb_eval_steps\n",
    "  ppl = torch.exp(torch.tensor(eval_loss))\n",
    "  return ppl.item()\n",
    "\n",
    "def prepare_eval(output_list):\n",
    "    ref_list, pred_list = [], []\n",
    "    for item in output_list:\n",
    "        pred_list.append({\"generated\": item['generated']})\n",
    "        ref_list.append({\"target\": [item['target']]})\n",
    "    return ref_list, pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "defb4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing dataset constructing function from utilities with a custom one.\n",
    "def parse_data(t_split='train'):\n",
    "\n",
    "  # Split handling - validation set further split into 50% dev/test.\n",
    "  if t_split == 'train':\n",
    "    df = pd.DataFrame(load_dataset('squad')['train'])\n",
    "  elif t_split in ['val','test']:\n",
    "    vt_df = pd.DataFrame(load_dataset('squad')['validation'])\n",
    "    df_val = vt_df.sample(frac=0.5,random_state=266)\n",
    "    if t_split == 'test':\n",
    "      df_test = vt_df.drop(df_val.index)\n",
    "      df = df_test\n",
    "    else:\n",
    "      df = df_val\n",
    "  else:\n",
    "    raise Exception(\"Invalid choice of dataset split.\")\n",
    "  \n",
    "\n",
    "  df['answer_text'] = df['answers'].apply(lambda x: x['text'][0])\n",
    "  df['source'] = 'answer: ' + df['answer_text'] + ' context: ' + df['context'] + '</s>'\n",
    "  df['target'] = df['question']\n",
    "\n",
    "  return df                                                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ce922db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary functions from GP-VAE implementation.\n",
    "\n",
    "if version.parse(torch.__version__) < version.parse(\"1.6\"):\n",
    "    from transformers.file_utils import is_apex_available\n",
    "\n",
    "    if is_apex_available():\n",
    "        from apex import amp\n",
    "    _use_apex = True\n",
    "else:\n",
    "    _use_native_amp = True\n",
    "    from torch.cuda.amp import autocast\n",
    "\n",
    "\n",
    "def init_linear_wt(linear):\n",
    "    linear.weight.data.normal_(std=1e-4)\n",
    "    if linear.bias is not None:\n",
    "        linear.bias.data.normal_(std=1e-4)\n",
    "\n",
    "\n",
    "class Seq2SeqModel(T5ForConditionalGeneration):\n",
    "    def __init__(self, config, *args, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.mean = nn.Linear(config.d_model, config.d_model)\n",
    "        init_linear_wt(self.mean)\n",
    "        self.logvar = nn.Linear(config.d_model, config.d_model)\n",
    "        init_linear_wt(self.logvar)\n",
    "        self.latent2hidden = nn.Linear(config.d_model, config.d_model, bias=False)\n",
    "        init_linear_wt(self.latent2hidden)\n",
    "        self.hidden2latent = nn.Linear(config.d_model, config.d_model)\n",
    "        init_linear_wt(self.hidden2latent)\n",
    "\n",
    "    def kernel_func(self, x, y):\n",
    "        \"\"\"\n",
    "        x, y - B x 2H\n",
    "        \"\"\"\n",
    "        cov_xy = self.kernel_v * torch.exp(-0.5 * torch.sum(torch.pow((x - y) / self.kernel_r, 2), dim=1))\n",
    "        return cov_xy\n",
    "\n",
    "    def prior(self, hidden_states):\n",
    "        \"\"\"\n",
    "        GP prior p(z|x) = N(mu(x), K(x, x'))\n",
    "        \n",
    "        enc_outputs - B x L x 2H\n",
    "        \"\"\"\n",
    "        b, l, h = list(hidden_states.size())\n",
    "        mean = hidden_states.sum(dim=2)  # B x L\n",
    "        mean = self.hidden2latent(hidden_states) # B x L x K\n",
    "        var = torch.zeros((b, l, l), requires_grad=False).cuda()  # B x L x L\n",
    "        for i in range(l):\n",
    "            for j in range(l):\n",
    "                var[:, i, j] = self.kernel_func(hidden_states[:, i, :], hidden_states[:, j, :])\n",
    "        return mean, var\n",
    "\n",
    "    def posterior(self, hidden_states):\n",
    "        \"\"\"\n",
    "        variational posterior q(z|x) = N(mu(x), f(x))\n",
    "        \n",
    "        mean, logvar - B x L x K\n",
    "        \"\"\"\n",
    "        mean = self.mean(hidden_states)  # B x L x K\n",
    "        logvar = self.logvar(hidden_states)  # B x L x K\n",
    "        mean = mean.sum(dim=2)  # B x L\n",
    "        x_var = torch.exp(logvar).sum(dim=2)  # B x L\n",
    "        var_batch = []\n",
    "        for b in range(mean.size(0)):\n",
    "            identity_matrix = torch.eye(x_var.size(1)).cuda()\n",
    "            var_batch.append(x_var[b] * identity_matrix)\n",
    "        var = torch.stack(var_batch, dim=0)  # B x L x L\n",
    "        return mean, var\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_() * self.scaler\n",
    "        eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def compute_kld(self, p_mean, p_var, q_mean, q_var):\n",
    "        k = p_var.size(1)\n",
    "        log_det = torch.logdet(p_var) - torch.logdet(q_var)\n",
    "        if torch.isnan(log_det).int().sum() > 0:\n",
    "            if torch.isnan(q_var).int().sum() > 0:\n",
    "                print('q_var has nan!!!')\n",
    "                print(q_var)\n",
    "        try:\n",
    "            p_var_inv = torch.inverse(p_var)  # B x L x L\n",
    "            trace_batch = torch.matmul(p_var_inv, q_var)  # B x L x L\n",
    "            trace_list = [torch.trace(trace_batch[i]) for i in range(trace_batch.size(0))]\n",
    "            trace = torch.stack(trace_list, dim=0)  # B\n",
    "            mean_diff = p_mean - q_mean.unsqueeze(2)  # B x L x 1\n",
    "           \n",
    "            mean = torch.matmul(torch.matmul(mean_diff.transpose(1, 2), p_var_inv), mean_diff)  # B x K x K\n",
    "\n",
    "            kld = log_det - k + trace + torch.mean(mean, dim=(1,2))\n",
    "            kld = 0.5 * kld  # B\n",
    "        except:\n",
    "            zeros = torch.zeros(p_mean.size(0)).cuda()\n",
    "            kld = zeros\n",
    "            print('zero kld!!!')\n",
    "        return kld.mean()\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids=None,\n",
    "            attention_mask=None,\n",
    "            decoder_input_ids=None,\n",
    "            decoder_attention_mask=None,\n",
    "            head_mask=None,\n",
    "            decoder_head_mask=None,\n",
    "            encoder_outputs=None,\n",
    "            past_key_values=None,\n",
    "            inputs_embeds=None,\n",
    "            decoder_inputs_embeds=None,\n",
    "            labels=None,\n",
    "            use_cache=None,\n",
    "            output_attentions=None,\n",
    "            output_hidden_states=None,\n",
    "            return_dict=None,\n",
    "    ):\n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        # FutureWarning: head_mask was separated into two input args - head_mask, decoder_head_mask\n",
    "        if head_mask is not None and decoder_head_mask is None:\n",
    "            if self.config.num_layers == self.config.num_decoder_layers:\n",
    "                decoder_head_mask = head_mask\n",
    "\n",
    "        # Encode if needed (training, first prediction pass)\n",
    "        if encoder_outputs is None:\n",
    "            # Convert encoder inputs in embeddings if needed\n",
    "            encoder_outputs = self.encoder(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                inputs_embeds=inputs_embeds,\n",
    "                head_mask=head_mask,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "                return_dict=return_dict,\n",
    "            )\n",
    "        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n",
    "            encoder_outputs = BaseModelOutput(\n",
    "                last_hidden_state=encoder_outputs[0],\n",
    "                hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n",
    "                attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n",
    "            )\n",
    "\n",
    "        hidden_states = encoder_outputs[0]\n",
    "        # added z code here\n",
    "        posterior_mean = self.mean(hidden_states)  # B x L x K\n",
    "        posterior_logvar = self.logvar(hidden_states)  # B x L x K\n",
    "\n",
    "        if self.from_mean:\n",
    "            z = posterior_mean\n",
    "        else:\n",
    "            z = self.reparameterize(posterior_mean, posterior_logvar)\n",
    "\n",
    "        input_proj = self.latent2hidden(z)  # B x L x K\n",
    "        hidden_states = hidden_states + input_proj\n",
    "\n",
    "        if self.model_parallel:\n",
    "            torch.cuda.set_device(self.decoder.first_device)\n",
    "\n",
    "        if labels is not None and decoder_input_ids is None and decoder_inputs_embeds is None:\n",
    "            # get decoder inputs from shifting lm labels to the right\n",
    "            decoder_input_ids = self._shift_right(labels)\n",
    "\n",
    "        # If decoding with past key value states, only the last tokens\n",
    "        # should be given as an input\n",
    "        if past_key_values is not None:\n",
    "            assert labels is None, \"Decoder should not use cached key value states when training.\"\n",
    "            if decoder_input_ids is not None:\n",
    "                decoder_input_ids = decoder_input_ids[:, -1:]\n",
    "            if decoder_inputs_embeds is not None:\n",
    "                decoder_inputs_embeds = decoder_inputs_embeds[:, -1:]\n",
    "\n",
    "        # Set device for model parallelism\n",
    "        if self.model_parallel:\n",
    "            torch.cuda.set_device(self.decoder.first_device)\n",
    "            hidden_states = hidden_states.to(self.decoder.first_device)\n",
    "            if decoder_input_ids is not None:\n",
    "                decoder_input_ids = decoder_input_ids.to(self.decoder.first_device)\n",
    "            if attention_mask is not None:\n",
    "                attention_mask = attention_mask.to(self.decoder.first_device)\n",
    "            if decoder_attention_mask is not None:\n",
    "                decoder_attention_mask = decoder_attention_mask.to(self.decoder.first_device)\n",
    "\n",
    "        # Decode\n",
    "        decoder_outputs = self.decoder(\n",
    "            input_ids=decoder_input_ids,\n",
    "            attention_mask=decoder_attention_mask,\n",
    "            inputs_embeds=decoder_inputs_embeds,\n",
    "            past_key_values=past_key_values,\n",
    "            encoder_hidden_states=hidden_states,\n",
    "            encoder_attention_mask=attention_mask,\n",
    "            head_mask=decoder_head_mask,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = decoder_outputs[0]\n",
    "\n",
    "        # Set device for model parallelism\n",
    "        if self.model_parallel:\n",
    "            torch.cuda.set_device(self.encoder.first_device)\n",
    "            self.lm_head = self.lm_head.to(self.encoder.first_device)\n",
    "            sequence_output = sequence_output.to(self.lm_head.weight.device)\n",
    "\n",
    "        if self.config.tie_word_embeddings:\n",
    "            # Rescale output before projecting on vocab\n",
    "            # See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\n",
    "            sequence_output = sequence_output * (self.model_dim ** -0.5)\n",
    "\n",
    "        lm_logits = self.lm_head(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "            loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), labels.view(-1))\n",
    "            # kl_loss\n",
    "            prior_mean, prior_logvar = self.prior(hidden_states)\n",
    "            posterior_mean, posterior_logvar = self.posterior(hidden_states)\n",
    "            kl_loss = self.compute_kld(prior_mean, prior_logvar, posterior_mean, posterior_logvar)\n",
    "            loss = loss + kl_loss\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (lm_logits,) + decoder_outputs[1:] + encoder_outputs\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return Seq2SeqLMOutput(\n",
    "            loss=loss,\n",
    "            logits=lm_logits,\n",
    "            past_key_values=decoder_outputs.past_key_values,\n",
    "            decoder_hidden_states=decoder_outputs.hidden_states,\n",
    "            decoder_attentions=decoder_outputs.attentions,\n",
    "            cross_attentions=decoder_outputs.cross_attentions,\n",
    "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
    "            encoder_hidden_states=encoder_outputs.hidden_states,\n",
    "            encoder_attentions=encoder_outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def prepare_inputs_for_generation(\n",
    "            self,\n",
    "            input_ids,\n",
    "            past=None,\n",
    "            attention_mask=None,\n",
    "            head_mask=None,\n",
    "            decoder_head_mask=None,\n",
    "            #        cross_attn_head_mask=None,\n",
    "            use_cache=None,\n",
    "            encoder_outputs=None,\n",
    "            **kwargs\n",
    "    ):\n",
    "\n",
    "        # cut decoder_input_ids if past is used\n",
    "        if past is not None:\n",
    "            input_ids = input_ids[:, -1:]\n",
    "\n",
    "        return {\n",
    "            \"decoder_input_ids\": input_ids,\n",
    "            \"past_key_values\": past,\n",
    "            \"encoder_outputs\": encoder_outputs,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"head_mask\": head_mask,\n",
    "            \"decoder_head_mask\": decoder_head_mask,\n",
    "            \"use_cache\": use_cache,\n",
    "        }\n",
    "\n",
    "\n",
    "class Seq2SeqTrainer(Trainer):\n",
    "    \"\"\"Class to finetune a Seq2Seq model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_beams=4,\n",
    "            max_length=32,\n",
    "            *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.num_beams = num_beams\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def compute_loss(self, model, inputs):\n",
    "        \"\"\"\n",
    "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "        Subclass and override for custom behavior.\n",
    "        \"\"\"\n",
    "        outputs = model(input_ids=inputs['input_ids'],\n",
    "                        # decoder_input_ids=inputs['labels'][:,:-1],\n",
    "                        labels=inputs['labels'])\n",
    "        if self.args.past_index >= 0:\n",
    "            self._past = outputs[self.args.past_index]\n",
    "\n",
    "        if self.label_smoother is not None and \"labels\" in inputs:\n",
    "            return self.label_smoother(outputs, inputs[\"labels\"])\n",
    "        else:\n",
    "            # We don't use .loss here since the model may return tuples instead of ModelOutput.\n",
    "            return outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        \"\"\"\n",
    "        Runs the model to either generate a sequence and/or compute the loss.\n",
    "        \"\"\"\n",
    "        has_labels = all(inputs.get(k) is not None for k in self.label_names)\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        # Compute loss with labels first.\n",
    "        with torch.no_grad():\n",
    "            if self.args.fp16 and _use_native_amp:\n",
    "                with autocast():\n",
    "                    outputs = model(input_ids=inputs['input_ids'],\n",
    "                                    # decoder_input_ids=inputs['labels'][:,:-1],\n",
    "                                    labels=inputs['labels'])\n",
    "            else:\n",
    "                outputs = model(input_ids=inputs['input_ids'],\n",
    "                                # decoder_input_ids=inputs['labels'][:,:-1],\n",
    "                                labels=inputs['labels'])\n",
    "            if has_labels:\n",
    "                loss = outputs[0].mean().detach()\n",
    "            else:\n",
    "                loss = None\n",
    "        # If we're only computing the conditional log-likelihood, return.\n",
    "        if prediction_loss_only:\n",
    "            return (loss, None, None)\n",
    "        # Otherwise run model.generate() to get predictions.\n",
    "        if isinstance(model, torch.nn.DataParallel):\n",
    "            preds = model.module.generate(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                num_beams=self.num_beams,\n",
    "                max_length=self.max_length,\n",
    "            )\n",
    "        else:\n",
    "            preds = model.generate(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                num_beams=self.num_beams,\n",
    "                max_length=self.max_length,\n",
    "            )\n",
    "        if len(preds) == 1:\n",
    "            preds = preds[0]\n",
    "        # Pad predictions if necessary so they can be concatenated across batches.\n",
    "        if preds.shape[-1] < self.max_length:\n",
    "            preds = torch.nn.functional.pad(\n",
    "                preds, (0, self.max_length - preds.shape[-1]),\n",
    "                mode='constant',\n",
    "                value=self.tokenizer.pad_token_id\n",
    "            )\n",
    "        # Post-process labels.\n",
    "        if has_labels:\n",
    "            labels = inputs.get('labels')\n",
    "        else:\n",
    "            labels = None\n",
    "        return (loss, preds, labels)\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    # Load the dataset\n",
    "    trn_df = parse_data('train', args)\n",
    "    val_df = parse_data('val', args)\n",
    "\n",
    "    # Load the pre-trained model\n",
    "    ckpt_path = None\n",
    "    if args.task == 'train':\n",
    "        ckpt_path = args.model_name\n",
    "    else:\n",
    "        ckpt_path = f\"{args.model_name}_{args.dataset}_{args.flag}_{args.kernel_v}_{args.kernel_r}_{args.timestamp}/checkpoint-{args.ckpt}\"\n",
    "        # update timestamp and create new path for ckpt\n",
    "        args.timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "\n",
    "    tokenizer = T5TokenizerFast.from_pretrained(ckpt_path)\n",
    "    print(f\"Vocab size: {len(tokenizer)}\")\n",
    "\n",
    "    train_data_tokenized = batchify_data(trn_df, tokenizer, args)\n",
    "    valid_data_tokenized = batchify_data(val_df, tokenizer, args)\n",
    "\n",
    "    model = Seq2SeqModel.from_pretrained(ckpt_path)\n",
    "    model = model.to('cuda:0')\n",
    "    model.kernel_v = args.kernel_v\n",
    "    model.kernel_r = args.kernel_r\n",
    "    model.from_mean = args.from_mean\n",
    "    model.scaler = 1.0\n",
    "\n",
    "    # Training Setup\n",
    "    train_args = TrainingArguments(\n",
    "        output_dir=f\"{args.model_name}_{args.dataset}_{args.flag}_{args.kernel_v}_{args.kernel_r}_{args.timestamp}\",\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=300,\n",
    "        #save_steps=120,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=300,\n",
    "        #eval_steps=120,\n",
    "        logging_steps=100,\n",
    "        # optimization args, the trainer uses the Adam optimizer\n",
    "        # and has a linear warmup for the learning rate\n",
    "        per_device_train_batch_size=args.batch_size,\n",
    "        per_device_eval_batch_size=args.batch_size,\n",
    "        gradient_accumulation_steps=1,\n",
    "        learning_rate=1e-04,\n",
    "        num_train_epochs=args.epochs,\n",
    "        warmup_steps=0,\n",
    "        lr_scheduler_type='constant',\n",
    "        # misc args\n",
    "        seed=42,\n",
    "        save_total_limit=5,  # limit the total amount of checkpoints\n",
    "        disable_tqdm=False,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        load_best_model_at_end=True,\n",
    "        greater_is_better=False,\n",
    "        local_rank=args.local_rank\n",
    "    )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        num_beams=args.beam_size,\n",
    "        max_length=args.decoder_max_length,\n",
    "        model=model,\n",
    "        args=train_args,\n",
    "        train_dataset=train_data_tokenized,\n",
    "        eval_dataset=valid_data_tokenized,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    # Now that we have the trainer set up, we can finetune.\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "def beam_generate_sentences(batch,\n",
    "                            model,\n",
    "                            tokenizer,\n",
    "                            args,\n",
    "                            device='cuda:0'):\n",
    "    # Create batch inputs.\n",
    "    features = make_batch_inputs(\n",
    "        batch=batch,\n",
    "        tokenizer=tokenizer,\n",
    "        args=args,\n",
    "        device=device)\n",
    "    # Generate with beam search.\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=features['input_ids'],\n",
    "        attention_mask=features['attention_mask'],\n",
    "        num_beams=args.beam_size,\n",
    "        max_length=args.max_generation_length,\n",
    "        num_return_sequences=args.num_return_sequences,\n",
    "    )\n",
    "    # Use model tokenizer to decode to text.\n",
    "    generated_sentences = [\n",
    "        tokenizer.decode(gen_ids.tolist(), skip_special_tokens=True)\n",
    "        for gen_ids in generated_ids\n",
    "    ]\n",
    "    #print(generated_sentences)\n",
    "    return ['\\t'.join(generated_sentences)]\n",
    "\n",
    "def nucleus_search_sentences(batch,\n",
    "                            model,\n",
    "                            tokenizer,\n",
    "                            args,\n",
    "                            device='cuda:0'):\n",
    "    # Create batch inputs.\n",
    "    features = make_batch_inputs(\n",
    "        batch=batch,\n",
    "        tokenizer=tokenizer,\n",
    "        args=args,\n",
    "        device=device)\n",
    "    # Generate with beam search.\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=features['input_ids'],\n",
    "        attention_mask=features['attention_mask'],\n",
    "        do_sample=True, \n",
    "        max_length=args.max_generation_length,\n",
    "        top_p=args.top_p, \n",
    "        top_k=args.top_k,\n",
    "        num_return_sequences=args.num_return_sequences\n",
    "    )\n",
    "    # Use model tokenizer to decode to text.\n",
    "    generated_sentences = [\n",
    "        tokenizer.decode(gen_ids.tolist(), skip_special_tokens=True)\n",
    "        for gen_ids in generated_ids\n",
    "    ]\n",
    "    #print(generated_sentences)\n",
    "    return ['\\t'.join(generated_sentences)]\n",
    "\n",
    "\n",
    "def sample_sentences(batch,\n",
    "                     model,\n",
    "                     tokenizer,\n",
    "                     args,\n",
    "                     device='cuda:0'):\n",
    "    # Create batch inputs.\n",
    "    features = make_batch_inputs(\n",
    "        batch=batch,\n",
    "        tokenizer=tokenizer,\n",
    "        args=args,\n",
    "        device=device)\n",
    "\n",
    "    generated_sentences = []\n",
    "    for i in range(args.num_return_sequences):\n",
    "        # Generate with beam search.\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=features['input_ids'],\n",
    "            attention_mask=features['attention_mask'],\n",
    "            num_beams=args.beam_size,\n",
    "            max_length=args.max_generation_length,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "        # Use model tokenizer to decode to text.\n",
    "        generated_sentences += [\n",
    "            tokenizer.decode(gen_ids.tolist(), skip_special_tokens=True)\n",
    "            for gen_ids in generated_ids\n",
    "        ]\n",
    "    #print(generated_sentences)\n",
    "    return ['\\t'.join(generated_sentences)]\n",
    "\n",
    "\n",
    "def test(args):\n",
    "    te_df = parse_data('test', args)\n",
    "    print('Data loaded!!!')\n",
    "\n",
    "    # Load the model\n",
    "    if args.timestamp == '0':\n",
    "        tokenizer = T5TokenizerFast.from_pretrained(f\"{args.model_name}\")\n",
    "    else:\n",
    "        ckpt_path = f\"{args.model_name}_{args.dataset}_{args.flag}_{args.kernel_v}_{args.kernel_r}_{args.timestamp}/checkpoint-{args.ckpt}\"\n",
    "        tokenizer = T5TokenizerFast.from_pretrained(ckpt_path)\n",
    "    print(f\"Vocab size: {len(tokenizer)}\")\n",
    "\n",
    "    if args.timestamp == '0':\n",
    "        model = Seq2SeqModel.from_pretrained(f\"{args.model_name}\")\n",
    "    else:\n",
    "        ckpt_path = f\"{args.model_name}_{args.dataset}_{args.flag}_{args.kernel_v}_{args.kernel_r}_{args.timestamp}/checkpoint-{args.ckpt}\"\n",
    "        model = Seq2SeqModel.from_pretrained(ckpt_path)\n",
    "    model = model.to('cuda:0')\n",
    "    model.kernel_v = args.kernel_v\n",
    "    model.kernel_r = args.kernel_r\n",
    "    model.from_mean = args.from_mean\n",
    "    model.scaler = args.scaler\n",
    "\n",
    "    # Make predictions\n",
    "    if args.from_mean:\n",
    "        test_output = Dataset.from_pandas(te_df).map(\n",
    "            lambda batch: {'generated': beam_generate_sentences(\n",
    "                batch,\n",
    "                model,\n",
    "                tokenizer,\n",
    "                args,\n",
    "                device='cuda:0')\n",
    "            },\n",
    "            batched=True,\n",
    "            batch_size=1,\n",
    "        )\n",
    "    else:\n",
    "        test_output = Dataset.from_pandas(te_df).map(\n",
    "            lambda batch: {'generated': sample_sentences(\n",
    "                batch,\n",
    "                model,\n",
    "                tokenizer,\n",
    "                args,\n",
    "                device='cuda:0')\n",
    "            },\n",
    "            batched=True,\n",
    "            batch_size=1,\n",
    "        )\n",
    "\n",
    "    # prepare evaluation data\n",
    "    ref_list, pred_list = prepare_eval(list(test_output))\n",
    "    reference_dict = {\n",
    "        \"language\": \"en\",\n",
    "        \"values\": ref_list,\n",
    "    }\n",
    "    prediction_dict = {\n",
    "        \"language\": \"en\",\n",
    "        \"values\": pred_list,\n",
    "    }\n",
    "\n",
    "    if args.timestamp == '0':\n",
    "        os.makedirs(f\"{args.model_name}_{args.dataset}_{args.flag}_{args.timestamp}\")\n",
    "\n",
    "    with open(\n",
    "            f\"{args.model_name}_{args.dataset}_{args.flag}_{args.kernel_v}_{args.kernel_r}_{args.timestamp}/refs.json\",\n",
    "            'w') as f:\n",
    "        f.write(json.dumps(reference_dict, indent=2))\n",
    "    if args.from_mean:\n",
    "        with open(\n",
    "                f\"{args.model_name}_{args.dataset}_{args.flag}_{args.kernel_v}_{args.kernel_r}_{args.timestamp}/outs_mean.json\",\n",
    "                'w') as f:\n",
    "            f.write(json.dumps(prediction_dict, indent=2))\n",
    "    else:\n",
    "        with open(\n",
    "                f\"{args.model_name}_{args.dataset}_{args.flag}_{args.kernel_v}_{args.kernel_r}_{args.timestamp}/outs.json\",\n",
    "                'w') as f:\n",
    "            f.write(json.dumps(prediction_dict, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8320e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = argparse.ArgumentParser(description='Hyperparams')\n",
    "p.add_argument('-t', '--task', type=str, default=\"train\",\n",
    "                help=\"specify the task to do: (train)ing, ft(finetune), (eval)uation\")\n",
    "p.add_argument('-c', '--ckpt', type=str, default=\"600\",\n",
    "                help=\"Model checkpoint\")\n",
    "p.add_argument('-time', '--timestamp', type=str, default='2022-07-19-01-04-50',\n",
    "                help=\"Model checkpoint\")\n",
    "p.add_argument('-f', '--flag', type=str, default='gpvae',\n",
    "                help=\"Model checkpoint\")\n",
    "p.add_argument('-d', '--dataset', type=str, default=\"GYAFC/em\",\n",
    "                help=\"specify the dataset: GYAFC/em, GYAFC/fr\")\n",
    "p.add_argument('--model_name', type=str, default=\"t5-base\",\n",
    "                help=\"specify the model name: t5-base, facebook/blenderbot-400M-distill\")\n",
    "p.add_argument('-v', '--kernel_v', type=float, default=100,\n",
    "                help=\"Hyper-parameter for prior kernel,  control the signal variance\")\n",
    "p.add_argument('-r', '--kernel_r', type=float, default=0.001,\n",
    "                help=\"Hyper-parameter for prior kernel.\")\n",
    "p.add_argument('-s', '--scaler', type=float, default=1.0)\n",
    "p.add_argument('--from_mean', action='store_true',\n",
    "                help=\"specify whether sample from mean during generation\")\n",
    "p.add_argument('-bz', '--batch_size', type=int, default=8)\n",
    "p.add_argument('-e', '--epochs', type=int, default=10)\n",
    "p.add_argument('--encoder_max_length', type=int, default=256)\n",
    "p.add_argument('--decoder_max_length', type=int, default=48)\n",
    "p.add_argument('--max_generation_length', type=int, default=96)\n",
    "p.add_argument('--beam_size', type=int, default=5)\n",
    "p.add_argument('--num_return_sequences', type=int, default=5)\n",
    "p.add_argument('--local_rank', type=int, default=-1,\n",
    "                help=\"Multiple GPU training\")\n",
    "args = p.parse_args()\n",
    "\n",
    "## jupyter fix for bad flag\n",
    "#args.flag = 't5base'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f62d461",
   "metadata": {},
   "source": [
    "### Generate predictions on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f51ce139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/ec2-user/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33022494b1ab4b64adef6648dd5e269c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d979e41b07a4529a736f74296e9add1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get tokenizer, model, and val set.\n",
    "#ckpt_path = f\"t5-base_GYAFC/em_gpvae_64.0_0.0001_2022-07-12-02-30-44/checkpoint-10800\"\n",
    "#ckpt_path = f\"t5-base_GYAFC/em_t5gpp128enc_64.0_0.0001_2022-07-16-14-35-44/checkpoint-4500\" # Pass A\n",
    "#ckpt_path = f\"t5-base_GYAFC/em_t5gpp128enc_64.0_0.0001_2022-07-17-17-38-30/checkpoint-5100\" # Pass B\n",
    "#ckpt_path = f\"t5-base_GYAFC/em_t5gpp128enc_64.0_0.0001_2022-07-19-01-04-50/checkpoint-600\" # Pass C\n",
    "#ckpt_path = \"t5-base_GYAFC/em_grid_e2_100.0_0.001_2022-07-22-02-22-41/checkpoint-5400\" # Best from grid search\n",
    "#ckpt_path = \"t5-base_GYAFC/em_grid_e3_100.0_0.01_2022-07-22-08-10-31/checkpoint-5400\" # 3rd best from grid search\n",
    "#ckpt_path = \"t5-base_GYAFC/em_grid_e4_100.0_0.1_2022-07-22-13-53-38/checkpoint-5400\" # 2nd best from grid search\n",
    "ckpt_path = \"t5-base_GYAFC/em_t5gpp256enc_64.0_0.0001_2022-07-16-04-29-17/checkpoint-10800\" # GPP with 256-length encoder\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained(ckpt_path)\n",
    "model = Seq2SeqModel.from_pretrained(ckpt_path)\n",
    "val_df = parse_data('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "204d7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other steps\n",
    "model = model.to('cuda:0')\n",
    "model.kernel_v = args.kernel_v\n",
    "model.kernel_r = args.kernel_r\n",
    "model.from_mean = args.from_mean\n",
    "model.scaler = args.scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef2e643d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff728eb231c41f7bfa98bfa8eff5fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "test_output = Dataset.from_pandas(val_df).map(\n",
    "    lambda batch: {'generated': beam_generate_sentences(\n",
    "        batch,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        args,\n",
    "        device='cuda:0')\n",
    "    },\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "# prepare evaluation data\n",
    "ref_list, pred_list = prepare_eval(list(test_output))\n",
    "reference_dict = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": ref_list,\n",
    "}\n",
    "prediction_dict = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": pred_list,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec31ff1",
   "metadata": {},
   "source": [
    "### Score predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "94efee0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 11.06835262894281,\n",
       " 'counts': [22716, 7218, 3534, 1853],\n",
       " 'totals': [59118, 53833, 48548, 43263],\n",
       " 'precisions': [38.42484522480463,\n",
       "  13.408132558096336,\n",
       "  7.279393589849222,\n",
       "  4.283105656103368],\n",
       " 'bp': 0.9831604147503054,\n",
       " 'sys_len': 59118,\n",
       " 'ref_len': 60122}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate BLEU-4.\n",
    "metric = datasets.load_metric('sacrebleu')\n",
    "fin_targets = [reference_dict['values'][x]['target'] for x in range(0,len(reference_dict['values']))]\n",
    "fin_preds = [prediction_dict['values'][x]['generated'].split('\\t')[0] for x in range(0,len(prediction_dict['values']))]\n",
    "for model_predictions, gold_references in zip(fin_preds,fin_targets):\n",
    "    metric.add(predictions=model_predictions, references=gold_references)\n",
    "final_score = metric.compute()\n",
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd3c4faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"answer: Newcastle Student Radio context: NE1fm launched on 8 June 2007, the first full-time community radio station in the area. Newcastle Student Radio is run by students from both of the city's universities, broadcasting from Newcastle University's student's union building during term time. Radio Tyneside has been the voluntary hospital radio service for most hospitals across Newcastle and Gateshead since 1951, broadcasting on Hospedia  and online. The city also has a Radio Lollipop station based at the Great North Children's Hospital in the Newcastle Royal Victoria Infirmary.</s>\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.iloc[25].source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad3a96",
   "metadata": {},
   "source": [
    "### Save or Load Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56ab42bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pred/target lists.\n",
    "with open('reference_dict_GPP256b.json', 'w') as fp:\n",
    "    json.dump(reference_dict, fp)\n",
    "with open('prediction_dict_GPP256b.json', 'w') as fp:\n",
    "    json.dump(prediction_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2944e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open pred/target lists.\n",
    "with open('reference_dict_GPP256b.json', 'r') as fp:\n",
    "    reference_dict = json.load(fp)\n",
    "with open('prediction_dict_GPP256b.json', 'r') as fp:\n",
    "    prediction_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925fe973",
   "metadata": {},
   "source": [
    "### Beam experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ff70c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c8473b613841bf908aee864c80c2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "args.beam_size = 10\n",
    "args.num_return_sequences = 10\n",
    "test_output = Dataset.from_pandas(val_df[:50]).map(\n",
    "    lambda batch: {'generated': beam_generate_sentences(\n",
    "        batch,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        args,\n",
    "        device='cuda:0')\n",
    "    },\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "# prepare evaluation data\n",
    "ref_list, pred_list = prepare_eval(list(test_output))\n",
    "reference_dict_test = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": ref_list,\n",
    "}\n",
    "prediction_dict_test = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": pred_list,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56fc7cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'answer: The UK context: The Social Charter was subsequently adopted in 1989 by 11 of the then 12 member states. The UK refused to sign the Social Charter and was exempt from the legislation covering Social Charter issues unless it agreed to be bound by the legislation. The UK subsequently was the only member state to veto the Social Charter being included as the \"Social Chapter\" of the 1992 Maastricht Treaty - instead, an Agreement on Social Policy was added as a protocol. Again, the UK was exempt from legislation arising from the protocol, unless it agreed to be bound by it. The protocol was to become known as \"Social Chapter\", despite not actually being a chapter of the Maastricht Treaty. To achieve aims of the Agreement on Social Policy the European Union was to \"support and complement\" the policies of member states. The aims of the Agreement on Social Policy are:</s>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.iloc[10].source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e9a2744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': ['Which member state declined to sign the Social Charter?']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_dict_test['values'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d22e95d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the name of a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be',\n",
       " 'What is the name of a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people?',\n",
       " 'What is the name of a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group?',\n",
       " 'What is the name of a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people?',\n",
       " 'What is the name of a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered a',\n",
       " 'What is the name of a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are not considered to be a group of people?',\n",
       " 'What is the name of a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people that are considered to be',\n",
       " 'What is the name of a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be part of a group of people?',\n",
       " 'What is the name of a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are not considered to',\n",
       " 'What is the name of a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people who are considered to be a group of people that are considered to be a group of people?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_dict_test['values'][17]['generated'].split('\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a954b",
   "metadata": {},
   "source": [
    "### Generate and save predictions for multiple sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e193095c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/ec2-user/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cdc790f90d47709a788207f86866cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c102a060eadd435f9ba8b97e9f2c943c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt3000  |  {'score': 4.693644469523313, 'counts': [19122, 4904, 2224, 1149], 'totals': [91961, 86676, 81391, 76106], 'precisions': [20.79359728580594, 5.657852231298168, 2.7324888501185636, 1.5097364202559589], 'bp': 1.0, 'sys_len': 91961, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0c355bede74af2966512006619926d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt3300  |  {'score': 5.807745533918182, 'counts': [19859, 5643, 2721, 1494], 'totals': [87695, 82410, 77125, 71840], 'precisions': [22.64553281258909, 6.847469967236986, 3.5280388978930306, 2.079621380846325], 'bp': 1.0, 'sys_len': 87695, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a8d44c4880405f92adf8e4459738b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt3600  |  {'score': 6.212544972894582, 'counts': [21772, 7051, 3556, 1977], 'totals': [100376, 95091, 89806, 84521], 'precisions': [21.690443930820116, 7.415002471316949, 3.9596463487962943, 2.3390636646513885], 'bp': 1.0, 'sys_len': 100376, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68570859db34a5688a6392654059958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt3900  |  {'score': 6.82551180183416, 'counts': [25177, 9225, 4782, 2690], 'totals': [116406, 111121, 105836, 100551], 'precisions': [21.62861020909575, 8.30176114325825, 4.518311349635285, 2.6752593211405156], 'bp': 1.0, 'sys_len': 116406, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b920f3b493247c1a1b68a6676eb8987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt4200  |  {'score': 8.39951916576026, 'counts': [25999, 9731, 5095, 2882], 'totals': [101062, 95777, 90492, 85207], 'precisions': [25.725792088025173, 10.160059304425905, 5.630331963046457, 3.3823512152757402], 'bp': 1.0, 'sys_len': 101062, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e49cb7dede4734b27e1310584f8f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt4500  |  {'score': 12.464174438135693, 'counts': [26210, 10239, 5598, 3257], 'totals': [75289, 70004, 64719, 59434], 'precisions': [34.8125224136328, 14.626307068167533, 8.649701015157836, 5.48002826664872], 'bp': 1.0, 'sys_len': 75289, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b0de151a68455db3c8619681084c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt4800  |  {'score': 12.213875750508853, 'counts': [26270, 10405, 5670, 3287], 'totals': [77350, 72065, 66780, 61495], 'precisions': [33.96250808015514, 14.438354263512107, 8.49056603773585, 5.345150012196114], 'bp': 1.0, 'sys_len': 77350, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c86c09a2c24953a19991ca3f7ec091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt5100  |  {'score': 15.031966522012546, 'counts': [25591, 9996, 5428, 3147], 'totals': [62338, 57053, 51768, 46483], 'precisions': [41.05200680162982, 17.52055106655215, 10.485241848246021, 6.770217068605727], 'bp': 1.0, 'sys_len': 62338, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986b0d15b84446d88912d0f9c82488df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt5400  |  {'score': 13.711000069825705, 'counts': [27133, 10726, 5848, 3419], 'totals': [71902, 66617, 61332, 56047], 'precisions': [37.736085227114685, 16.100995241454886, 9.534989891084589, 6.100237300836798], 'bp': 1.0, 'sys_len': 71902, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d233c80d4d43b29a5128ddb21df719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt5700  |  {'score': 13.818584075234822, 'counts': [26432, 10558, 5752, 3348], 'totals': [70170, 64885, 59600, 54315], 'precisions': [37.668519310246545, 16.271865608384065, 9.651006711409396, 6.164043082021541], 'bp': 1.0, 'sys_len': 70170, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f2bd492c7c4cbf8e3320ca5d6a61bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt6000  |  {'score': 13.803321544924831, 'counts': [26223, 10170, 5530, 3208], 'totals': [68302, 63017, 57732, 52447], 'precisions': [38.392726420895436, 16.138502308900772, 9.578743158040602, 6.116651095391538], 'bp': 1.0, 'sys_len': 68302, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4778ce0726304e1c9245e57a5173db44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt6300  |  {'score': 15.013156174785042, 'counts': [26137, 10138, 5522, 3225], 'totals': [63450, 58165, 52880, 47595], 'precisions': [41.19306540583136, 17.429725780108313, 10.44251134644478, 6.775921840529468], 'bp': 1.0, 'sys_len': 63450, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507d59a2401f467193c6e6f82b83a7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt6600  |  {'score': 15.177581264505072, 'counts': [25819, 10009, 5433, 3164], 'totals': [62042, 56757, 51472, 46187], 'precisions': [41.61535733857709, 17.634829184065403, 10.55525334162263, 6.850412453720744], 'bp': 1.0, 'sys_len': 62042, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa79b64681f4090935394d11b8e8681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt6900  |  {'score': 13.876068448931703, 'counts': [25429, 9707, 5265, 3045], 'totals': [65392, 60107, 54822, 49537], 'precisions': [38.88701981893809, 16.149533332224202, 9.603808689941994, 6.1469204836788665], 'bp': 1.0, 'sys_len': 65392, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93b79e3e7e54d43ad87e8db89de0671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt7200  |  {'score': 15.842365519783677, 'counts': [26146, 10195, 5510, 3142], 'totals': [60289, 55004, 49719, 44434], 'precisions': [43.36777853339747, 18.53501563522653, 11.082282427241095, 7.071161723004906], 'bp': 1.0, 'sys_len': 60289, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4415c6abf7a4f13a27285e3a9b58a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt7500  |  {'score': 11.651170887269602, 'counts': [22833, 7553, 3769, 1986], 'totals': [56908, 51623, 46338, 41053], 'precisions': [40.12265410838546, 14.63107529589524, 8.133713151193405, 4.837648892894551], 'bp': 0.9450881069496168, 'sys_len': 56908, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f83290e0ea4b3a956bc8b2bf93a3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt7800  |  {'score': 17.360430015067553, 'counts': [27227, 11267, 6247, 3649], 'totals': [60934, 55649, 50364, 45079], 'precisions': [44.68277152328749, 20.246545310787255, 12.403701056310062, 8.094678231549059], 'bp': 1.0, 'sys_len': 60934, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceaeacbf617e4985ba2532df30cd17f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt8100  |  {'score': 16.924576967521308, 'counts': [26493, 10762, 5934, 3455], 'totals': [58711, 53426, 48141, 42856], 'precisions': [45.12442302123963, 20.14375023396848, 12.326291518663925, 8.061881650177337], 'bp': 0.9762535171880073, 'sys_len': 58711, 'ref_len': 60122}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "paths = ['t5-base_GYAFC/256_backup/checkpoint-' + str(x) for x in range(3000,8400,300)]\n",
    "names = ['ckpt' + str(x) for x in range(3000,8400,300)]\n",
    "\n",
    "# Get data\n",
    "val_df = parse_data('val')\n",
    "\n",
    "# Main loop\n",
    "for x in range (18):\n",
    "    tokenizer = T5TokenizerFast.from_pretrained(paths[x])\n",
    "    model = Seq2SeqModel.from_pretrained(paths[x])\n",
    "    model = model.to('cuda:0')\n",
    "    model.kernel_v = args.kernel_v\n",
    "    model.kernel_r = args.kernel_r\n",
    "    model.from_mean = True\n",
    "    model.scaler = args.scaler\n",
    "    \n",
    "    # Make predictions\n",
    "    test_output = Dataset.from_pandas(val_df).map(\n",
    "        lambda batch: {'generated': beam_generate_sentences(\n",
    "            batch,\n",
    "            model,\n",
    "            tokenizer,\n",
    "            args,\n",
    "            device='cuda:0')\n",
    "        },\n",
    "        batched=True,\n",
    "        batch_size=1,\n",
    "    )\n",
    "\n",
    "    # prepare evaluation data\n",
    "    ref_list, pred_list = prepare_eval(list(test_output))\n",
    "    reference_dict = {\n",
    "        \"language\": \"en\",\n",
    "        \"values\": ref_list,\n",
    "    }\n",
    "    prediction_dict = {\n",
    "        \"language\": \"en\",\n",
    "        \"values\": pred_list,\n",
    "    }\n",
    "    \n",
    "    # Save pred/target lists.\n",
    "    with open(names[x] + '_reference_dict.json', 'w') as fp:\n",
    "        json.dump(reference_dict, fp)\n",
    "    with open(names[x] + '_prediction_dict.json', 'w') as fp:\n",
    "        json.dump(prediction_dict, fp)\n",
    "        \n",
    "    # Calculate BLEU-4.\n",
    "    metric = datasets.load_metric('sacrebleu')\n",
    "    fin_targets = [reference_dict['values'][x]['target'] for x in range(0,len(reference_dict['values']))]\n",
    "    fin_preds = [prediction_dict['values'][x]['generated'].split('\\t')[0] for x in range(0,len(prediction_dict['values']))]\n",
    "    for model_predictions, gold_references in zip(fin_preds,fin_targets):\n",
    "        metric.add(predictions=model_predictions, references=gold_references)\n",
    "    final_score = metric.compute()\n",
    "    print(names[x], ' | ', final_score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f8038",
   "metadata": {},
   "source": [
    "### Nucleus search experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d966731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/ec2-user/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9dc9d9ac104bacbe5ff8457f19c982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958be1be1be6491cb7e3d0b842f4399f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ckpt_path = \"t5-base_GYAFC/em_grid_e2_100.0_0.001_2022-07-22-02-22-41/checkpoint-5400\" # Best from grid search\n",
    "#ckpt_path = \"t5-base_GYAFC/em_grid_e3_100.0_0.01_2022-07-22-08-10-31/checkpoint-5400\" # 3rd best from grid search\n",
    "#ckpt_path = \"t5-base_GYAFC/em_grid_e4_100.0_0.1_2022-07-22-13-53-38/checkpoint-5400\" # 2nd best from grid search\n",
    "ckpt_path = \"t5-base_GYAFC/256_backup/checkpoint-7800\"\n",
    "\n",
    "# Get model and data.\n",
    "tokenizer = T5TokenizerFast.from_pretrained(ckpt_path)\n",
    "model = Seq2SeqModel.from_pretrained(ckpt_path)\n",
    "val_df = parse_data('val')\n",
    "valid_data_tokenized = batchify_data(val_df, tokenizer, args)\n",
    "\n",
    "# Other steps.\n",
    "model = model.to('cuda:0')\n",
    "model.kernel_v = 100 #args.kernel_v\n",
    "model.kernel_r = 0.001 #args.kernel_r\n",
    "model.from_mean = args.from_mean\n",
    "model.scaler = args.scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "914b62a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c2a2b33f1946f9942ceb5ff3ab7f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "args.top_p = 0.5\n",
    "args.top_k = 5\n",
    "args.num_return_sequences = 10\n",
    "\n",
    "test_output2 = Dataset.from_pandas(val_df).map(\n",
    "    lambda batch: {'generated': nucleus_search_sentences(\n",
    "        batch,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        args,\n",
    "        device='cuda:0')\n",
    "    },\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "# prepare evaluation data\n",
    "ref_list2, pred_list2 = prepare_eval(list(test_output))\n",
    "reference_dict2 = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": ref_list2,\n",
    "}\n",
    "prediction_dict2 = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": pred_list2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2947509d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 8.60465608915507,\n",
       " 'counts': [205, 58, 26, 13],\n",
       " 'totals': [550, 500, 450, 400],\n",
       " 'precisions': [37.27272727272727, 11.6, 5.777777777777778, 3.25],\n",
       " 'bp': 0.9064840734837171,\n",
       " 'sys_len': 550,\n",
       " 'ref_len': 604}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate BLEU-4.\n",
    "metric = datasets.load_metric('sacrebleu')\n",
    "fin_targets = [reference_dict2['values'][x]['target'] for x in range(0,len(reference_dict2['values']))]\n",
    "fin_preds = [prediction_dict2['values'][x]['generated'].split('\\t')[0] for x in range(0,len(prediction_dict2['values']))]\n",
    "for model_predictions, gold_references in zip(fin_preds,fin_targets):\n",
    "    metric.add(predictions=model_predictions, references=gold_references)\n",
    "final_score = metric.compute()\n",
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ad66b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Which member state declined to sign the Social Charter?']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_dict_test['values'][10]['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "956c9035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What was the purpose of the Agreement on Social Policy?',\n",
       " 'What did the UK refuse to sign the Treaty of Maastricht?',\n",
       " 'What did the UK refuse to sign?',\n",
       " 'What was the purpose of the agreement on Social Policy?',\n",
       " 'What was the purpose of the Treaty of Maastricht?',\n",
       " 'What was the name of the agreement that the UK refused to sign?',\n",
       " 'What did the UK refuse to sign the Social Charter?',\n",
       " 'What did the UK refuse to sign the Treaty on Social Policy?',\n",
       " 'What was the purpose of the agreement?',\n",
       " 'What was the purpose of the agreement on social policy?']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_dict_test['values'][10]['generated'].split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6434a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'answer: The UK context: The Social Charter was subsequently adopted in 1989 by 11 of the then 12 member states. The UK refused to sign the Social Charter and was exempt from the legislation covering Social Charter issues unless it agreed to be bound by the legislation. The UK subsequently was the only member state to veto the Social Charter being included as the \"Social Chapter\" of the 1992 Maastricht Treaty - instead, an Agreement on Social Policy was added as a protocol. Again, the UK was exempt from legislation arising from the protocol, unless it agreed to be bound by it. The protocol was to become known as \"Social Chapter\", despite not actually being a chapter of the Maastricht Treaty. To achieve aims of the Agreement on Social Policy the European Union was to \"support and complement\" the policies of member states. The aims of the Agreement on Social Policy are:</s>'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.iloc[10].source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72c9f8e",
   "metadata": {},
   "source": [
    "### Nucleus search and top-k combination grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dd5da28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b733a8544341b7b19fe3e7291e257c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p= 0.5   k= 100   {'score': 14.137242087308438, 'counts': [25007, 9072, 4705, 2606], 'totals': [56196, 50911, 45626, 40341], 'precisions': [44.499608513061425, 17.819331775058437, 10.312102748432912, 6.459929104385117], 'bp': 0.9325219175416379, 'sys_len': 56196, 'ref_len': 60122}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9239fd0bc754f0780f7b15c0fccd3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p= 0.6   k= 5   {'score': 13.973700972325515, 'counts': [24883, 9097, 4658, 2514], 'totals': [55986, 50701, 45416, 40131], 'precisions': [44.44503983138642, 17.94244689453857, 10.256297340144442, 6.2644838155042235], 'bp': 0.9287872168634487, 'sys_len': 55986, 'ref_len': 60122}\n"
     ]
    }
   ],
   "source": [
    "pk_list = [(0.5,100),(0.6,5)]\n",
    "\n",
    "for x in range(len(pk_list)):\n",
    "    # Make predictions\n",
    "    args.top_p = pk_list[x][0]\n",
    "    args.top_k = pk_list[x][1]\n",
    "\n",
    "    test_output = Dataset.from_pandas(val_df).map(\n",
    "        lambda batch: {'generated': nucleus_search_sentences(\n",
    "            batch,\n",
    "            model,\n",
    "            tokenizer,\n",
    "            args,\n",
    "            device='cuda:0')\n",
    "        },\n",
    "        batched=True,\n",
    "        batch_size=1,\n",
    "    )\n",
    "\n",
    "    # prepare evaluation data\n",
    "    ref_list, pred_list = prepare_eval(list(test_output))\n",
    "    reference_dict_test = {\n",
    "        \"language\": \"en\",\n",
    "        \"values\": ref_list,\n",
    "    }\n",
    "    prediction_dict_test = {\n",
    "        \"language\": \"en\",\n",
    "        \"values\": pred_list,\n",
    "    }\n",
    "    \n",
    "    # Calculate BLEU-4.\n",
    "    metric = datasets.load_metric('sacrebleu')\n",
    "    fin_targets = [reference_dict_test['values'][x]['target'] for x in range(0,len(reference_dict_test['values']))]\n",
    "    fin_preds = [prediction_dict_test['values'][x]['generated'].split('\\t')[0] for x in range(0,len(prediction_dict_test['values']))]\n",
    "    for model_predictions, gold_references in zip(fin_preds,fin_targets):\n",
    "        metric.add(predictions=model_predictions, references=gold_references)\n",
    "    final_score = metric.compute()\n",
    "    print('p=',args.top_p,' ',\n",
    "          'k=',args.top_k,' ',\n",
    "        final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470e9d0e",
   "metadata": {},
   "source": [
    "### Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "96cbf5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqModel(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       "  (mean): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (logvar): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (latent2hidden): Linear(in_features=768, out_features=768, bias=False)\n",
       "  (hidden2latent): Linear(in_features=768, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "caa264de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=768, bias=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.latent2hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f84cb5",
   "metadata": {},
   "source": [
    "### Test on novel examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3485001c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0986884e094e430d823b740c17a6f656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Batman context: The Justice League is made up of many heroes. Superman is an alien with super strength, x-ray vision, and the ability to fly. Batman uses his vast wealth to buy gadgets. Wonder Woman is an Amazon princess with an invisible jet, bulletproof bracelets, and a lasso of truth. The Flash is just really fast.\n",
      "Who is the richest member of the Justice League?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What is the name of the superhero in the Justice League?',\n",
       " \"What is Superman's role in the Justice League?\",\n",
       " \"What is Batman's role in the Justice League?\",\n",
       " 'What is the name of the superhero who has the ability to fly?',\n",
       " \"What is the name of the superhero in Batman's Justice League?\",\n",
       " \"What is Superman's name?\",\n",
       " \"What is Superman's nickname?\",\n",
       " \"What is the name of Batman's favorite superhero?\",\n",
       " \"What is Superman's role in the Justice League called?\",\n",
       " 'What is the name of the superhero who has the power to fly?']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize beam size and return sequences.\n",
    "args.beam_size = 10\n",
    "args.num_return_sequences = 10\n",
    "\n",
    "# Example A - Superhero Question\n",
    "novel_answer = \"Batman\"\n",
    "novel_context = \"The Justice League is made up of many heroes. Superman is an alien with super strength, x-ray vision, and the ability to fly. Batman uses his vast wealth to buy gadgets. Wonder Woman is an Amazon princess with an invisible jet, bulletproof bracelets, and a lasso of truth. The Flash is just really fast.\"\n",
    "novel_df = pd.DataFrame()\n",
    "novel_df['source'] = [\"answer: \" + novel_answer + \" context: \" + novel_context]\n",
    "novel_df['target'] = ['Who is the richest member of the Justice League?']\n",
    "novel_df['id'] = 0\n",
    "\n",
    "\n",
    "novel_example_output = Dataset.from_pandas(novel_df).map(\n",
    "    lambda batch: {'generated': beam_generate_sentences(\n",
    "        batch,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        args,\n",
    "        device='cuda:0')\n",
    "    },\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "novel_example_output\n",
    "\n",
    "# Prepare evaluation data\n",
    "novel_refs_list, novel_preds_list = prepare_eval(list(novel_example_output))\n",
    "\n",
    "# Show output\n",
    "novel_preds_list[0]['generated'].split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cc12dabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca542644f2704ac8ad3c758c2d5a260a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Stochastic gradient descent context: Stochastic gradient descent (often abbreviated SGD) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in high-dimensional optimization problems this reduces the very high computational burden, achieving faster iterations in trade for a lower convergence rate.\n",
      "What does SGD stand for?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What does SGD stand for?',\n",
       " 'What is the acronym for SGD?',\n",
       " 'What is an example of a stochastic gradient descent?',\n",
       " 'What is a synonym for SGD?',\n",
       " 'What is SGD?',\n",
       " 'What is SGD also known as?',\n",
       " 'What is the acronym of SGD?',\n",
       " 'What is an example of a stochastic approach to gradient descent?',\n",
       " 'What is the name of the process that optimizes an objective function?',\n",
       " 'What is an example of a stochastic gradient descent technique?']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize beam size and return sequences.\n",
    "args.beam_size = 10\n",
    "args.num_return_sequences = 10\n",
    "\n",
    "# Example B - Machine Learning\n",
    "novel_answer = \"Stochastic gradient descent\"\n",
    "novel_context = \"Stochastic gradient descent (often abbreviated SGD) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in high-dimensional optimization problems this reduces the very high computational burden, achieving faster iterations in trade for a lower convergence rate.\"\n",
    "novel_df = pd.DataFrame()\n",
    "novel_df['source'] = [\"answer: \" + novel_answer + \" context: \" + novel_context]\n",
    "novel_df['target'] = ['What does SGD stand for?']\n",
    "novel_df['id'] = 0\n",
    "\n",
    "\n",
    "novel_example_output = Dataset.from_pandas(novel_df).map(\n",
    "    lambda batch: {'generated': beam_generate_sentences(\n",
    "        batch,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        args,\n",
    "        device='cuda:0')\n",
    "    },\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "novel_example_output\n",
    "\n",
    "# Prepare evaluation data\n",
    "novel_refs_list, novel_preds_list = prepare_eval(list(novel_example_output))\n",
    "\n",
    "# Show output\n",
    "novel_preds_list[0]['generated'].split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "72d745c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbe32f8c09641f8820d83d2c81c9991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 1066 context: William I, usually known as William the Conqueror and sometimes William the Bastard, was the first Norman king of England, reigning from 1066 until his death in 1087. A descendant of Rollo, he was Duke of Normandy from 1035 onward. By 1060, following a long struggle to establish his throne, his hold on Normandy was secure. In 1066, following the death of Edward the Confessor, William invaded England, leading an army of Normans to victory over the Anglo-Saxon forces of Harold Godwinson at the Battle of Hastings, and suppressed subsequent English revolts in what has become known as the Norman Conquest. The rest of his life was marked by struggles to consolidate his hold over England and his continental lands, and by difficulties with his eldest son, Robert Curthose.\n",
      "At which battle did William the Conqueror defeat Harold Godwinson?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What year was William the Conqueror king of England?',\n",
       " 'What year was William I king of England?',\n",
       " 'What was the name of the first Norman king of England?',\n",
       " \"What was William the Conqueror's name?\",\n",
       " 'What year did William I reign as king of England?',\n",
       " 'What year was William the Conqueror born?',\n",
       " 'What year was William the Conqueror king of England crowned?',\n",
       " \"What was William the Conqueror's title?\",\n",
       " 'What year was William the Conqueror king of England born?',\n",
       " 'What year was William the Conqueror king?']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize beam size and return sequences.\n",
    "args.beam_size = 10\n",
    "args.num_return_sequences = 10\n",
    "\n",
    "# Example C - World History\n",
    "novel_answer = \"1066\"\n",
    "novel_context = \"William I, usually known as William the Conqueror and sometimes William the Bastard, was the first Norman king of England, reigning from 1066 until his death in 1087. A descendant of Rollo, he was Duke of Normandy from 1035 onward. By 1060, following a long struggle to establish his throne, his hold on Normandy was secure. In 1066, following the death of Edward the Confessor, William invaded England, leading an army of Normans to victory over the Anglo-Saxon forces of Harold Godwinson at the Battle of Hastings, and suppressed subsequent English revolts in what has become known as the Norman Conquest. The rest of his life was marked by struggles to consolidate his hold over England and his continental lands, and by difficulties with his eldest son, Robert Curthose.\"\n",
    "novel_df = pd.DataFrame()\n",
    "novel_df['source'] = [\"answer: \" + novel_answer + \" context: \" + novel_context]\n",
    "novel_df['target'] = ['At which battle did William the Conqueror defeat Harold Godwinson?']\n",
    "novel_df['id'] = 0\n",
    "\n",
    "\n",
    "novel_example_output = Dataset.from_pandas(novel_df).map(\n",
    "    lambda batch: {'generated': beam_generate_sentences(\n",
    "        batch,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        args,\n",
    "        device='cuda:0')\n",
    "    },\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "novel_example_output\n",
    "\n",
    "# Prepare evaluation data\n",
    "novel_refs_list, novel_preds_list = prepare_eval(list(novel_example_output))\n",
    "\n",
    "# Show output\n",
    "novel_preds_list[0]['generated'].split('\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2743d9",
   "metadata": {},
   "source": [
    "### Final predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e31e467b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/ec2-user/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4e0ed970b94795840f770777cf1959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8846e2648a44435d9eadbb4c3f87bd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 16.56587608025032, 'counts': [26599, 10808, 5858, 3296], 'totals': [60367, 55082, 49797, 44512], 'precisions': [44.062153163152054, 19.621654987110126, 11.763760869128662, 7.404744787922358], 'bp': 1.0, 'sys_len': 60367, 'ref_len': 59985}\n"
     ]
    }
   ],
   "source": [
    "# Make predictions (Beam)\n",
    "test_df = parse_data('test')\n",
    "\n",
    "test_output = Dataset.from_pandas(test_df).map(\n",
    "    lambda batch: {'generated': beam_generate_sentences(\n",
    "        batch,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        args,\n",
    "        device='cuda:0')\n",
    "    },\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "# prepare evaluation data\n",
    "ref_list, pred_list = prepare_eval(list(test_output))\n",
    "reference_dict = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": ref_list,\n",
    "}\n",
    "prediction_dict = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": pred_list,\n",
    "}\n",
    "\n",
    "# Calculate BLEU-4.\n",
    "metric = datasets.load_metric('sacrebleu')\n",
    "fin_targets = [reference_dict['values'][x]['target'] for x in range(0,len(reference_dict['values']))]\n",
    "fin_preds = [prediction_dict['values'][x]['generated'].split('\\t')[0] for x in range(0,len(prediction_dict['values']))]\n",
    "for model_predictions, gold_references in zip(fin_preds,fin_targets):\n",
    "    metric.add(predictions=model_predictions, references=gold_references)\n",
    "final_score = metric.compute()\n",
    "print(final_score)\n",
    "\n",
    "# Save pred/target lists.\n",
    "with open('FINAL_reference_dict_GPP256.json', 'w') as fp:\n",
    "    json.dump(reference_dict, fp)\n",
    "with open('FINAL_prediction_dict_GPP256.json', 'w') as fp:\n",
    "    json.dump(prediction_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c653b032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/ec2-user/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ad960a38c14bf4aa4ecb6ed2e6d64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ce254ffafc4df6b279c01420732131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 13.64246031118634, 'counts': [24541, 8930, 4546, 2397], 'totals': [56158, 50873, 45588, 40303], 'precisions': [43.699918088251, 17.553515617321565, 9.9719224357287, 5.947448080788031], 'bp': 0.9341231345067288, 'sys_len': 56158, 'ref_len': 59985}\n"
     ]
    }
   ],
   "source": [
    "# Make predictions (Nucleus)\n",
    "test_df = parse_data('test')\n",
    "args.top_p = 0.5\n",
    "args.top_k = 100\n",
    "\n",
    "test_output = Dataset.from_pandas(test_df).map(\n",
    "        lambda batch: {'generated': nucleus_search_sentences(\n",
    "            batch,\n",
    "            model,\n",
    "            tokenizer,\n",
    "            args,\n",
    "            device='cuda:0')\n",
    "        },\n",
    "        batched=True,\n",
    "        batch_size=1,\n",
    "    )\n",
    "\n",
    "# prepare evaluation data\n",
    "ref_list, pred_list = prepare_eval(list(test_output))\n",
    "reference_dict = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": ref_list,\n",
    "}\n",
    "prediction_dict = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": pred_list,\n",
    "}\n",
    "\n",
    "# Calculate BLEU-4.\n",
    "metric = datasets.load_metric('sacrebleu')\n",
    "fin_targets = [reference_dict['values'][x]['target'] for x in range(0,len(reference_dict['values']))]\n",
    "fin_preds = [prediction_dict['values'][x]['generated'].split('\\t')[0] for x in range(0,len(prediction_dict['values']))]\n",
    "for model_predictions, gold_references in zip(fin_preds,fin_targets):\n",
    "    metric.add(predictions=model_predictions, references=gold_references)\n",
    "final_score = metric.compute()\n",
    "print(final_score)\n",
    "\n",
    "# Save pred/target lists.\n",
    "with open('FINAL_NS_reference_dict_GPP256.json', 'w') as fp:\n",
    "    json.dump(reference_dict, fp)\n",
    "with open('FINAL_NS_prediction_dict_GPP256.json', 'w') as fp:\n",
    "    json.dump(prediction_dict, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
