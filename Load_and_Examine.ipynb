{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e73d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 03:31:37.902484: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-07-30 03:31:37.906641: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-30 03:31:37.906655: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Import block\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.modeling_outputs import BaseModelOutput, Seq2SeqLMOutput\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from packaging import version\n",
    "\n",
    "from datasets import list_datasets, load_dataset, list_metrics, load_metric\n",
    "from datasets import Dataset\n",
    "\n",
    "import sacrebleu\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ee1450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions from GP-VAE implementation\n",
    "\n",
    "# Specific to dataset.\n",
    "def construct_input_for_batch(tokenizer, batch, args):\n",
    "    \"\"\"\n",
    "    Function that takes a batch from a dataset and constructs the corresponding \n",
    "    input string.\n",
    "    \"\"\"\n",
    "    source, target = [], []\n",
    "    for inp, out in zip(batch['source'], batch['target']):\n",
    "        source.append(inp.strip())\n",
    "        target.append(out.strip())\n",
    "    if batch['id'][0] == 0:\n",
    "        print(source[0])\n",
    "        print(target[0])\n",
    "        print()\n",
    "    return source, target\n",
    "\n",
    "def make_batch_inputs(batch, tokenizer, args, device='cuda:0'):\n",
    "  \"\"\"\n",
    "  Function that takes a batch from a dataset and transforms it \n",
    "  \"\"\"\n",
    "  # Concatenate the concept names for each example in the batch.\n",
    "  input_lists, _ = construct_input_for_batch(tokenizer, batch, args)\n",
    "  # Use the model's tokenizer to create the batch input_ids.\n",
    "  batch_features = tokenizer(input_lists, padding=True, return_tensors='pt')\n",
    "  # Move all inputs to the device.\n",
    "  batch_features = dict([(k, v.to(device)) for k, v in batch_features.items()])\n",
    "  return batch_features\n",
    "\n",
    "def make_batch_data(batch, tokenizer, args, device='cuda:0'):\n",
    "  \"\"\"\n",
    "  Function that takes a batch from a dataset and transforms it \n",
    "  \"\"\"\n",
    "  # Concatenate the concept names for each example in the batch.\n",
    "  input_lists, label_list = construct_input_for_batch(tokenizer, batch, args)\n",
    "  # Use the model's tokenizer to create the batch input_ids.\n",
    "  batch_features = tokenizer(input_lists, padding=True, return_tensors='pt')\n",
    "  batch_labels = tokenizer(label_list, padding=True, return_tensors='pt')\n",
    "  # Move all inputs to the device.\n",
    "  batch_features = dict([(k, v.to(device)) for k, v in batch_features.items()])\n",
    "  batch_labels = dict([(k, v.to(device)) for k, v in batch_labels.items()])\n",
    "  return batch_features, batch_labels\n",
    "\n",
    "def batch_tokenize(dataset_batch, tokenizer, args):\n",
    "  \"\"\"\n",
    "  Reuse the function defined above to construct the batch (source, target) and \n",
    "  run them through the tokenizer.\n",
    "  \"\"\"\n",
    "  source, target = construct_input_for_batch(tokenizer, dataset_batch, args)\n",
    "  res = {\n",
    "          \"input_ids\": tokenizer(\n",
    "              source,\n",
    "              padding='max_length', \n",
    "              truncation=True,\n",
    "              max_length=args.encoder_max_length\n",
    "          )[\"input_ids\"],\n",
    "          \"labels\": tokenizer(\n",
    "              target,\n",
    "              padding='max_length', \n",
    "              truncation=True,\n",
    "              max_length=args.decoder_max_length\n",
    "          )[\"input_ids\"],\n",
    "  }\n",
    "  return res\n",
    "\n",
    "def batchify_data(df, tokenizer, args):\n",
    "  dataset = Dataset.from_pandas(df)\n",
    "  data_tokenized = dataset.map(\n",
    "    lambda batch: batch_tokenize(batch, tokenizer, args),\n",
    "    batched=True\n",
    "  )\n",
    "  return data_tokenized\n",
    "\n",
    "def compute_loss(batch, model, tokenizer, args):\n",
    "  batch_feature, batch_label = make_batch_data(batch, tokenizer, args)\n",
    "  with torch.no_grad():\n",
    "    outputs = model(input_ids=batch_feature['input_ids'],\n",
    "                    labels=batch_label['input_ids'])\n",
    "    eval_loss = outputs.loss.item()\n",
    "  return [eval_loss] \n",
    "\n",
    "def test_ppl(val_df, model, tokenizer, args):\n",
    "  loss_dict = Dataset.from_pandas(val_df).map(\n",
    "    lambda batch: {'loss': compute_loss(batch, model, tokenizer, args)},\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    "  )\n",
    "  \n",
    "  eval_loss = 0.\n",
    "  nb_eval_steps = 0\n",
    "  for item in list(loss_dict):\n",
    "      eval_loss += item['loss']\n",
    "      nb_eval_steps += 1\n",
    "  eval_loss = eval_loss / nb_eval_steps\n",
    "  ppl = torch.exp(torch.tensor(eval_loss))\n",
    "  return ppl.item()\n",
    "\n",
    "def prepare_eval(output_list):\n",
    "    ref_list, pred_list = [], []\n",
    "    for item in output_list:\n",
    "        pred_list.append({\"generated\": item['generated']})\n",
    "        ref_list.append({\"target\": [item['target']]})\n",
    "    return ref_list, pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "defb4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing dataset constructing function from utilities with a custom one.\n",
    "def parse_data(t_split='train'):\n",
    "\n",
    "  # Split handling - validation set further split into 50% dev/test.\n",
    "  if t_split == 'train':\n",
    "    df = pd.DataFrame(load_dataset('squad')['train'])\n",
    "  elif t_split in ['val','test']:\n",
    "    vt_df = pd.DataFrame(load_dataset('squad')['validation'])\n",
    "    df_val = vt_df.sample(frac=0.5,random_state=266)\n",
    "    if t_split == 'test':\n",
    "      df_test = vt_df.drop(df_val.index)\n",
    "      df = df_test\n",
    "    else:\n",
    "      df = df_val\n",
    "  else:\n",
    "    raise Exception(\"Invalid choice of dataset split.\")\n",
    "  \n",
    "\n",
    "  df['answer_text'] = df['answers'].apply(lambda x: x['text'][0])\n",
    "  df['source'] = 'answer: ' + df['answer_text'] + ' context: ' + df['context'] + '</s>'\n",
    "  df['target'] = df['question']\n",
    "\n",
    "  return df                                                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ce922db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if version.parse(torch.__version__) < version.parse(\"1.6\"):\n",
    "    from transformers.file_utils import is_apex_available\n",
    "\n",
    "    if is_apex_available():\n",
    "        from apex import amp\n",
    "    _use_apex = True\n",
    "else:\n",
    "    _use_native_amp = True\n",
    "    from torch.cuda.amp import autocast\n",
    "\n",
    "class Seq2SeqTrainer(Trainer):\n",
    "    \"\"\"Class to finetune a Seq2Seq model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_beams=4,\n",
    "            max_length=32,\n",
    "            *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.num_beams = num_beams\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def compute_loss(self, model, inputs):\n",
    "        \"\"\"\n",
    "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "        Subclass and override for custom behavior.\n",
    "        \"\"\"\n",
    "        outputs = model(input_ids=inputs['input_ids'],\n",
    "                        # decoder_input_ids=inputs['labels'][:,:-1],\n",
    "                        labels=inputs['labels'])\n",
    "        if self.args.past_index >= 0:\n",
    "            self._past = outputs[self.args.past_index]\n",
    "\n",
    "        if self.label_smoother is not None and \"labels\" in inputs:\n",
    "            return self.label_smoother(outputs, inputs[\"labels\"])\n",
    "        else:\n",
    "            # We don't use .loss here since the model may return tuples instead of ModelOutput.\n",
    "            return outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        \"\"\"\n",
    "        Runs the model to either generate a sequence and/or compute the loss.\n",
    "        \"\"\"\n",
    "        has_labels = all(inputs.get(k) is not None for k in self.label_names)\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        # Compute loss with labels first.\n",
    "        with torch.no_grad():\n",
    "            if self.args.fp16 and _use_native_amp:\n",
    "                with autocast():\n",
    "                    outputs = model(input_ids=inputs['input_ids'],\n",
    "                                    # decoder_input_ids=inputs['labels'][:,:-1],\n",
    "                                    labels=inputs['labels'])\n",
    "            else:\n",
    "                outputs = model(input_ids=inputs['input_ids'],\n",
    "                                # decoder_input_ids=inputs['labels'][:,:-1],\n",
    "                                labels=inputs['labels'])\n",
    "            if has_labels:\n",
    "                loss = outputs[0].mean().detach()\n",
    "            else:\n",
    "                loss = None\n",
    "        # If we're only computing the conditional log-likelihood, return.\n",
    "        if prediction_loss_only:\n",
    "            return (loss, None, None)\n",
    "        # Otherwise run model.generate() to get predictions.\n",
    "        if isinstance(model, torch.nn.DataParallel):\n",
    "            preds = model.module.generate(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                num_beams=self.num_beams,\n",
    "                max_length=self.max_length,\n",
    "            )\n",
    "        else:\n",
    "            preds = model.generate(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                num_beams=self.num_beams,\n",
    "                max_length=self.max_length,\n",
    "            )\n",
    "        if len(preds) == 1:\n",
    "            preds = preds[0]\n",
    "        # Pad predictions if necessary so they can be concatenated across batches.\n",
    "        if preds.shape[-1] < self.max_length:\n",
    "            preds = torch.nn.functional.pad(\n",
    "                preds, (0, self.max_length - preds.shape[-1]),\n",
    "                mode='constant',\n",
    "                value=self.tokenizer.pad_token_id\n",
    "            )\n",
    "        # Post-process labels.\n",
    "        if has_labels:\n",
    "            labels = inputs.get('labels')\n",
    "        else:\n",
    "            labels = None\n",
    "        return (loss, preds, labels)\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    # Load the dataset\n",
    "    trn_df = parse_data('train')\n",
    "    val_df = parse_data('val')\n",
    "\n",
    "    # Load the pre-trained model\n",
    "    ckpt_path = None\n",
    "    if args.task == 'train':\n",
    "        ckpt_path = args.model_name\n",
    "    else:\n",
    "        ckpt_path = f\"{args.model_name}_{args.dataset}_{args.flag}_{args.kernel_v}_{args.kernel_r}_{args.timestamp}/checkpoint-{args.ckpt}\"\n",
    "        # update timestamp and create new path for ckpt\n",
    "        args.timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "\n",
    "    tokenizer = T5TokenizerFast.from_pretrained(ckpt_path)\n",
    "    print(f\"Vocab size: {len(tokenizer)}\")\n",
    "\n",
    "    train_data_tokenized = batchify_data(trn_df, tokenizer, args)\n",
    "    valid_data_tokenized = batchify_data(val_df, tokenizer, args)\n",
    "\n",
    "    model = T5ForConditionalGeneration.from_pretrained(ckpt_path)\n",
    "    model = model.to('cuda:0')\n",
    "\n",
    "    # Training Setup\n",
    "    train_args = TrainingArguments(\n",
    "        output_dir=f\"{args.model_name}_{args.dataset}_{args.flag}_{args.kernel_v}_{args.kernel_r}_{args.timestamp}\",\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=300,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=300,\n",
    "        logging_steps=100,\n",
    "        # optimization args, the trainer uses the Adam optimizer\n",
    "        # and has a linear warmup for the learning rate\n",
    "        per_device_train_batch_size=args.batch_size,\n",
    "        per_device_eval_batch_size=args.batch_size,\n",
    "        gradient_accumulation_steps=1,\n",
    "        learning_rate=1e-04,\n",
    "        num_train_epochs=args.epochs,\n",
    "        warmup_steps=0,\n",
    "        lr_scheduler_type='constant',\n",
    "        # misc args\n",
    "        seed=42,\n",
    "        save_total_limit=5,  # limit the total amount of checkpoints\n",
    "        disable_tqdm=False,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        load_best_model_at_end=True,\n",
    "        greater_is_better=False,\n",
    "        local_rank=args.local_rank\n",
    "    )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        num_beams=args.beam_size,\n",
    "        max_length=args.decoder_max_length,\n",
    "        model=model,\n",
    "        args=train_args,\n",
    "        train_dataset=train_data_tokenized,\n",
    "        eval_dataset=valid_data_tokenized,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    # Now that we have the trainer set up, we can finetune.\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "def beam_generate_sentences(batch,\n",
    "                            model,\n",
    "                            tokenizer,\n",
    "                            args,\n",
    "                            device='cuda:0'):\n",
    "    # Create batch inputs.\n",
    "    features = make_batch_inputs(\n",
    "        batch=batch,\n",
    "        tokenizer=tokenizer,\n",
    "        args=args,\n",
    "        device=device)\n",
    "    # Generate with beam search.\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=features['input_ids'],\n",
    "        attention_mask=features['attention_mask'],\n",
    "        num_beams=args.beam_size,\n",
    "        max_length=args.max_generation_length,\n",
    "        num_return_sequences=args.num_return_sequences,\n",
    "    )\n",
    "    # Use model tokenizer to decode to text.\n",
    "    generated_sentences = [\n",
    "        tokenizer.decode(gen_ids.tolist(), skip_special_tokens=True)\n",
    "        for gen_ids in generated_ids\n",
    "    ]\n",
    "    # print(generated_sentences)\n",
    "    return ['\\t'.join(generated_sentences)]\n",
    "\n",
    "def nucleus_search_sentences(batch,\n",
    "                            model,\n",
    "                            tokenizer,\n",
    "                            args,\n",
    "                            device='cuda:0'):\n",
    "    # Create batch inputs.\n",
    "    features = make_batch_inputs(\n",
    "        batch=batch,\n",
    "        tokenizer=tokenizer,\n",
    "        args=args,\n",
    "        device=device)\n",
    "    # Generate with nucleus search.\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=features['input_ids'],\n",
    "        attention_mask=features['attention_mask'],\n",
    "        do_sample=True, \n",
    "        max_length=args.max_generation_length,\n",
    "        top_p=args.top_p, \n",
    "        top_k=args.top_k,\n",
    "        num_return_sequences=args.num_return_sequences\n",
    "    )\n",
    "    # Use model tokenizer to decode to text.\n",
    "    generated_sentences = [\n",
    "        tokenizer.decode(gen_ids.tolist(), skip_special_tokens=True)\n",
    "        for gen_ids in generated_ids\n",
    "    ]\n",
    "    #print(generated_sentences)\n",
    "    return ['\\t'.join(generated_sentences)]\n",
    "\n",
    "def sample_sentences(batch,\n",
    "                     model,\n",
    "                     tokenizer,\n",
    "                     args,\n",
    "                     device='cuda:0'):\n",
    "    # Create batch inputs.\n",
    "    features = make_batch_inputs(\n",
    "        batch=batch,\n",
    "        tokenizer=tokenizer,\n",
    "        args=args,\n",
    "        device=device)\n",
    "\n",
    "    generated_sentences = []\n",
    "    for i in range(args.num_return_sequences):\n",
    "        # Generate with beam search.\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=features['input_ids'],\n",
    "            attention_mask=features['attention_mask'],\n",
    "            num_beams=args.beam_size,\n",
    "            max_length=args.max_generation_length,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "        # Use model tokenizer to decode to text.\n",
    "        generated_sentences += [\n",
    "            tokenizer.decode(gen_ids.tolist(), skip_special_tokens=True)\n",
    "            for gen_ids in generated_ids\n",
    "        ]\n",
    "    # print(generated_sentences)\n",
    "    return ['\\t'.join(generated_sentences)]\n",
    "\n",
    "\n",
    "def test(args):\n",
    "    te_df = parse_data('test')\n",
    "    print('Data loaded!!!')\n",
    "\n",
    "    # Load the model\n",
    "    if args.timestamp == '0':\n",
    "        tokenizer = T5TokenizerFast.from_pretrained(f\"{args.model_name}\")\n",
    "    else:\n",
    "        ckpt_path = f\"{args.model_name}_{args.dataset}_{args.flag}_{args.kernel_v}_{args.kernel_r}_{args.timestamp}/checkpoint-{args.ckpt}\"\n",
    "        tokenizer = T5TokenizerFast.from_pretrained(ckpt_path)\n",
    "    print(f\"Vocab size: {len(tokenizer)}\")\n",
    "\n",
    "    if args.timestamp == '0':\n",
    "        model = T5ForConditionalGeneration.from_pretrained(f\"{args.model_name}\")\n",
    "    else:\n",
    "        ckpt_path = f\"{args.model_name}_{args.dataset}_{args.flag}_{args.kernel_v}_{args.kernel_r}_{args.timestamp}/checkpoint-{args.ckpt}\"\n",
    "        model = T5ForConditionalGeneration.from_pretrained(ckpt_path)\n",
    "    model = model.to('cuda:0')\n",
    "    model.kernel_v = args.kernel_v\n",
    "    model.kernel_r = args.kernel_r\n",
    "    model.from_mean = args.from_mean\n",
    "    model.scaler = args.scaler\n",
    "\n",
    "    # Make predictions\n",
    "    if args.from_mean:\n",
    "        test_output = Dataset.from_pandas(te_df).map(\n",
    "            lambda batch: {'generated': beam_generate_sentences(\n",
    "                batch,\n",
    "                model,\n",
    "                tokenizer,\n",
    "                args,\n",
    "                device='cuda:0')\n",
    "            },\n",
    "            batched=True,\n",
    "            batch_size=1,\n",
    "        )\n",
    "    else:\n",
    "        test_output = Dataset.from_pandas(te_df).map(\n",
    "            lambda batch: {'generated': sample_sentences(\n",
    "                batch,\n",
    "                model,\n",
    "                tokenizer,\n",
    "                args,\n",
    "                device='cuda:0')\n",
    "            },\n",
    "            batched=True,\n",
    "            batch_size=1,\n",
    "        )\n",
    "\n",
    "    # prepare evaluation data\n",
    "    ref_list, pred_list = prepare_eval(list(test_output))\n",
    "    reference_dict = {\n",
    "        \"language\": \"en\",\n",
    "        \"values\": ref_list,\n",
    "    }\n",
    "    prediction_dict = {\n",
    "        \"language\": \"en\",\n",
    "        \"values\": pred_list,\n",
    "    }\n",
    "\n",
    "    if args.timestamp == '0':\n",
    "        os.makedirs(f\"{args.model_name}_{args.dataset}_{args.flag}_{args.timestamp}\")\n",
    "\n",
    "    with open(\n",
    "            f\"{args.model_name}_{args.dataset}_{args.flag}_{args.kernel_v}_{args.kernel_r}_{args.timestamp}/refs.json\",\n",
    "            'w') as f:\n",
    "        f.write(json.dumps(reference_dict, indent=2))\n",
    "    if args.from_mean:\n",
    "        with open(\n",
    "                f\"{args.model_name}_{args.dataset}_{args.flag}_{args.kernel_v}_{args.kernel_r}_{args.timestamp}/outs_mean.json\",\n",
    "                'w') as f:\n",
    "            f.write(json.dumps(prediction_dict, indent=2))\n",
    "    else:\n",
    "        with open(\n",
    "                f\"{args.model_name}_{args.dataset}_{args.flag}_{args.kernel_v}_{args.kernel_r}_{args.timestamp}/outs.json\",\n",
    "                'w') as f:\n",
    "            f.write(json.dumps(prediction_dict, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8320e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = argparse.ArgumentParser(description='Hyperparams')\n",
    "p.add_argument('-t', '--task', type=str, default=\"train\",\n",
    "                help=\"specify the task to do: (train)ing, ft(finetune), (eval)uation\")\n",
    "p.add_argument('-c', '--ckpt', type=str, default=\"193280\",\n",
    "                help=\"Model checkpoint\")\n",
    "p.add_argument('-time', '--timestamp', type=str, default='2021-02-14-04-57-04',\n",
    "                help=\"Model checkpoint\")\n",
    "p.add_argument('-f', '--flag', type=str, default='gpvae',\n",
    "                help=\"Model checkpoint\")\n",
    "p.add_argument('-d', '--dataset', type=str, default=\"GYAFC/em\",\n",
    "                help=\"specify the dataset: GYAFC/em, GYAFC/fr\")\n",
    "p.add_argument('--model_name', type=str, default=\"t5-base\",\n",
    "                help=\"specify the model name: t5-base, facebook/blenderbot-400M-distill\")\n",
    "p.add_argument('-v', '--kernel_v', type=float, default=64.0,\n",
    "                help=\"Hyper-parameter for prior kernel,  control the signal variance\")\n",
    "p.add_argument('-r', '--kernel_r', type=float, default=0.0001,\n",
    "                help=\"Hyper-parameter for prior kernel.\")\n",
    "p.add_argument('-s', '--scaler', type=float, default=1.0)\n",
    "p.add_argument('--from_mean', action='store_true',\n",
    "                help=\"specify whether sample from mean during generation\")\n",
    "p.add_argument('-bz', '--batch_size', type=int, default=8)\n",
    "p.add_argument('-e', '--epochs', type=int, default=10)\n",
    "p.add_argument('--encoder_max_length', type=int, default=256)\n",
    "p.add_argument('--decoder_max_length', type=int, default=48)\n",
    "p.add_argument('--max_generation_length', type=int, default=96)\n",
    "p.add_argument('--beam_size', type=int, default=5)\n",
    "p.add_argument('--num_return_sequences', type=int, default=5)\n",
    "p.add_argument('--local_rank', type=int, default=-1,\n",
    "                help=\"Multiple GPU training\")\n",
    "args = p.parse_args()\n",
    "\n",
    "# jupyter fix for bad flag\n",
    "args.flag = 't5base'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f62d461",
   "metadata": {},
   "source": [
    "### Generate predictions on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f51ce139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/ec2-user/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06bf5c8c72b44dd382792f8af03c78bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get tokenizer, model, and dev set.\n",
    "#ckpt_path = f\"t5-base_GYAFC/em_gpvae_64.0_0.0001_2022-07-12-02-30-44/checkpoint-10800\"\n",
    "#ckpt_path = f\"t5-base_GYAFC/em_t5gpp128enc_64.0_0.0001_2022-07-16-14-35-44/checkpoint-4500\"\n",
    "ckpt_path = \"t5-base_SQuAD_t5baseline256enc_64.0_0.0001_2022-07-14-16-30-47/checkpoint-2700\"\n",
    "#ckpt_path = \"t5-base_SQuAD_t5baseline512enc_64.0_0.0001_2022-07-14-22-30-45/checkpoint-2700\"\n",
    "#ckpt_path = \"t5-base_SQuAD_t5baseline128enc_64.0_0.0001_2022-07-14-20-27-33/checkpoint-2700\"\n",
    "#ckpt_path = \"t5-base_SQuAD_t5baseline64enc_64.0_0.0001_2022-07-14-15-23-46/checkpoint-1200\"\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained(ckpt_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(ckpt_path)\n",
    "val_df = parse_data('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "204d7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other steps\n",
    "model = model.to('cuda:0')\n",
    "model.kernel_v = args.kernel_v\n",
    "model.kernel_r = args.kernel_r\n",
    "model.from_mean = args.from_mean\n",
    "model.scaler = args.scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6eb8b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/ec2-user/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d833444ea144b07b87b57669773adc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "test_output = Dataset.from_pandas(val_df).map(\n",
    "    lambda batch: {'generated': beam_generate_sentences(\n",
    "        batch,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        args,\n",
    "        device='cuda:0')\n",
    "    },\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "# prepare evaluation data\n",
    "ref_list, pred_list = prepare_eval(list(test_output))\n",
    "reference_dict = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": ref_list,\n",
    "}\n",
    "prediction_dict = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": pred_list,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec31ff1",
   "metadata": {},
   "source": [
    "### Score predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94efee0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 21.832873266861107,\n",
       " 'counts': [29570, 13727, 8038, 4922],\n",
       " 'totals': [57892, 52607, 47322, 42037],\n",
       " 'precisions': [51.077869135631865,\n",
       "  26.093485657802194,\n",
       "  16.98575715312117,\n",
       "  11.708732783024479],\n",
       " 'bp': 0.9622124576388367,\n",
       " 'sys_len': 57892,\n",
       " 'ref_len': 60122}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate BLEU-4.\n",
    "metric = datasets.load_metric('sacrebleu')\n",
    "fin_targets = [reference_dict['values'][x]['target'] for x in range(0,len(reference_dict['values']))]\n",
    "fin_preds = [prediction_dict['values'][x]['generated'].split('\\t')[0] for x in range(0,len(prediction_dict['values']))]\n",
    "for model_predictions, gold_references in zip(fin_preds,fin_targets):\n",
    "    metric.add(predictions=model_predictions, references=gold_references)\n",
    "final_score = metric.compute()\n",
    "final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad3a96",
   "metadata": {},
   "source": [
    "### Save or Load Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56ab42bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pred/target lists.\n",
    "with open('reference_dict_base256.json', 'w') as fp:\n",
    "    json.dump(reference_dict, fp)\n",
    "with open('prediction_dict_base256.json', 'w') as fp:\n",
    "    json.dump(prediction_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2944e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open pred/target lists.\n",
    "with open('reference_dict_base256.json', 'r') as fp:\n",
    "    reference_dict = json.load(fp)\n",
    "with open('prediction_dict_base256.json', 'r') as fp:\n",
    "    prediction_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925fe973",
   "metadata": {},
   "source": [
    "### Beam experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ff70c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383ffa17b79745e68d3d945c5c9766ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "test_output = Dataset.from_pandas(val_df[0:5]).map(\n",
    "        lambda batch: {'generated': beam_generate_sentences(\n",
    "            batch,\n",
    "            model,\n",
    "            tokenizer,\n",
    "            args,\n",
    "            device='cuda:0')\n",
    "        },\n",
    "        batched=True,\n",
    "        batch_size=1,\n",
    "    )\n",
    "\n",
    "# prepare evaluation data\n",
    "ref_list, pred_list = prepare_eval(list(test_output))\n",
    "reference_dict = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": ref_list,\n",
    "}\n",
    "prediction_dict = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": pred_list,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56fc7cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9318     answer: 1421 context: Before the St. Elizabeth...\n",
       "10432    answer: applied force context: Pushing against...\n",
       "3106     answer: Huguon context: In this last connectio...\n",
       "5685     answer: Serge Chermayeff context: One of the e...\n",
       "7684     answer: the Museum of the Moving Image context...\n",
       "Name: source, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[0:5].source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e9a2744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': ['What year did the flood that impacted the Meuse take place?']},\n",
       " {'target': ['What makes static friction go up or down in responce to contact characteristics between an object and the surface it is on?']},\n",
       " {'target': ['By what other name was the Gate known?']},\n",
       " {'target': ['A rug by which Russian-born British designer is included in the V&A collection?']},\n",
       " {'target': ['Who put on a Doctor Who exhibition in 1991?']}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_dict['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d22e95d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Who named their exhibition \"Behind the Sofa\"?',\n",
       " 'Who named their exhibition \"Behind the Sofa\" in 1991?',\n",
       " 'Which museum in London named their exhibition \"Behind the Sofa\"?',\n",
       " \"Who named their exhibition 'Behind the Sofa'?\",\n",
       " 'Who named the exhibition \"Behind the Sofa\"?']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_dict['values'][4]['generated'].split('\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e85adbd",
   "metadata": {},
   "source": [
    "### Generate and save predictions for multiple sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44878444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/ec2-user/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bd5279b9ef4514b5174131f4497251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function <lambda> at 0x7f6ded75f0e0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbce79513bc1432a9904a51094ce8b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam64  |  {'score': 20.613766611394976, 'counts': [30098, 13600, 7839, 4697], 'totals': [62003, 56718, 51433, 46148], 'precisions': [48.54281244455913, 23.97827850065235, 15.241187564404177, 10.178122562191211], 'bp': 1.0, 'sys_len': 62003, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8661db3f2c6c464eb0f5476f70845c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam128  |  {'score': 21.832873266861107, 'counts': [29570, 13727, 8038, 4922], 'totals': [57892, 52607, 47322, 42037], 'precisions': [51.077869135631865, 26.093485657802194, 16.98575715312117, 11.708732783024479], 'bp': 0.9622124576388367, 'sys_len': 57892, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7188e0e0bc9244ef89c2d7af01ec9341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam256  |  {'score': 22.156978729604877, 'counts': [29891, 13929, 8212, 5059], 'totals': [59419, 54134, 48849, 43564], 'precisions': [50.3054578501826, 25.730594450807256, 16.810988965997257, 11.61279955926912], 'bp': 0.9882384813920382, 'sys_len': 59419, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7731fcab12f14a6dbb466a623950deeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam512  |  {'score': 22.027947806309555, 'counts': [30214, 13941, 8118, 4958], 'totals': [59726, 54441, 49156, 43871], 'precisions': [50.58768375581823, 25.60753843610514, 16.51476930588331, 11.301315219621163], 'bp': 0.9933916535261289, 'sys_len': 59726, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5442/2806245587.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Main loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5TokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "paths = [\"t5-base_SQuAD_t5baseline64enc_64.0_0.0001_2022-07-14-15-23-46/checkpoint-1200\",\n",
    "\"t5-base_SQuAD_t5baseline128enc_64.0_0.0001_2022-07-14-20-27-33/checkpoint-2700\",         \n",
    "\"t5-base_SQuAD_t5baseline256enc_64.0_0.0001_2022-07-14-16-30-47/checkpoint-2700\",\n",
    "\"t5-base_SQuAD_t5baseline512enc_64.0_0.0001_2022-07-14-22-30-45/checkpoint-2700\"]\n",
    "names = ['nucleus64', 'nucleus128', 'nucleus256', 'nucleus512']\n",
    "\n",
    "# Get data\n",
    "val_df = parse_data('val')\n",
    "\n",
    "# Main loop\n",
    "for x in range (len(names)):\n",
    "    tokenizer = T5TokenizerFast.from_pretrained(paths[x])\n",
    "    model = T5ForConditionalGeneration.from_pretrained(paths[x])\n",
    "    model = model.to('cuda:0')\n",
    "    model.kernel_v = args.kernel_v\n",
    "    model.kernel_r = args.kernel_r\n",
    "    model.from_mean = True\n",
    "    model.scaler = args.scaler\n",
    "    \n",
    "    # Make predictions\n",
    "    test_output = Dataset.from_pandas(val_df).map(\n",
    "        lambda batch: {'generated': beam_generate_sentences(\n",
    "            batch,\n",
    "            model,\n",
    "            tokenizer,\n",
    "            args,\n",
    "            device='cuda:0')\n",
    "        },\n",
    "        batched=True,\n",
    "        batch_size=1,\n",
    "    )\n",
    "\n",
    "    # prepare evaluation data\n",
    "    ref_list, pred_list = prepare_eval(list(test_output))\n",
    "    reference_dict = {\n",
    "        \"language\": \"en\",\n",
    "        \"values\": ref_list,\n",
    "    }\n",
    "    prediction_dict = {\n",
    "        \"language\": \"en\",\n",
    "        \"values\": pred_list,\n",
    "    }\n",
    "    \n",
    "    # Save pred/target lists.\n",
    "    with open(names[x] + '_reference_dict.json', 'w') as fp:\n",
    "        json.dump(reference_dict, fp)\n",
    "    with open(names[x] + '_prediction_dict.json', 'w') as fp:\n",
    "        json.dump(prediction_dict, fp)\n",
    "        \n",
    "    # Calculate BLEU-4.\n",
    "    metric = datasets.load_metric('sacrebleu')\n",
    "    fin_targets = [reference_dict['values'][x]['target'] for x in range(0,len(reference_dict['values']))]\n",
    "    fin_preds = [prediction_dict['values'][x]['generated'].split('\\t')[0] for x in range(0,len(prediction_dict['values']))]\n",
    "    for model_predictions, gold_references in zip(fin_preds,fin_targets):\n",
    "        metric.add(predictions=model_predictions, references=gold_references)\n",
    "    final_score = metric.compute()\n",
    "    print(names[x], ' | ', final_score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8aa12440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/ec2-user/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b94028570b14576b916b8d060727f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa34ab46067e47e6a8dfdcd323111260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top p = 0.5 top k = 10  |  {'score': 19.119924463130687, 'counts': [27786, 12089, 6797, 3988], 'totals': [52696, 47411, 42126, 36841], 'precisions': [52.72885987551237, 25.498302081795362, 16.13492854769026, 10.824896175456692], 'bp': 0.8685574803018126, 'sys_len': 52696, 'ref_len': 60122}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933719c031374a959eb5800a9098e27e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top p = 0.5 top k = 100  |  {'score': 18.705496682099312, 'counts': [27562, 11870, 6636, 3847], 'totals': [52986, 47701, 42416, 37131], 'precisions': [52.01751406031782, 24.8841743359678, 15.645039607695209, 10.360615119441976], 'bp': 0.8739980936452628, 'sys_len': 52986, 'ref_len': 60122}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "tokenizer = T5TokenizerFast.from_pretrained('t5-base_SQuAD_t5baseline256enc_64.0_0.0001_2022-07-14-16-30-47/checkpoint-2700')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base_SQuAD_t5baseline256enc_64.0_0.0001_2022-07-14-16-30-47/checkpoint-2700')\n",
    "model = model.to('cuda:0')\n",
    "model.kernel_v = args.kernel_v\n",
    "model.kernel_r = args.kernel_r\n",
    "model.from_mean = True\n",
    "model.scaler = args.scaler\n",
    "\n",
    "pk_list = [(0.5,3),(0.5,10),(0.5,100)]\n",
    "\n",
    "# Get data\n",
    "val_df = parse_data('val')\n",
    "\n",
    "# Main loop\n",
    "for x in range (len(pk_list)):\n",
    "    args.top_p = pk_list[x][0]\n",
    "    args.top_k = pk_list[x][1]\n",
    "    \n",
    "    # Make predictions\n",
    "    test_output = Dataset.from_pandas(val_df).map(\n",
    "        lambda batch: {'generated': nucleus_search_sentences(\n",
    "            batch,\n",
    "            model,\n",
    "            tokenizer,\n",
    "            args,\n",
    "            device='cuda:0')\n",
    "        },\n",
    "        batched=True,\n",
    "        batch_size=1,\n",
    "    )\n",
    "\n",
    "    # prepare evaluation data\n",
    "    ref_list, pred_list = prepare_eval(list(test_output))\n",
    "    reference_dict = {\n",
    "        \"language\": \"en\",\n",
    "        \"values\": ref_list,\n",
    "    }\n",
    "    prediction_dict = {\n",
    "        \"language\": \"en\",\n",
    "        \"values\": pred_list,\n",
    "    }\n",
    "    \n",
    "        \n",
    "    # Calculate BLEU-4.\n",
    "    metric = datasets.load_metric('sacrebleu')\n",
    "    fin_targets = [reference_dict['values'][x]['target'] for x in range(0,len(reference_dict['values']))]\n",
    "    fin_preds = [prediction_dict['values'][x]['generated'].split('\\t')[0] for x in range(0,len(prediction_dict['values']))]\n",
    "    for model_predictions, gold_references in zip(fin_preds,fin_targets):\n",
    "        metric.add(predictions=model_predictions, references=gold_references)\n",
    "    final_score = metric.compute()\n",
    "    print('top p =', args.top_p,'top k =', args.top_k ,' | ', final_score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09ecc79",
   "metadata": {},
   "source": [
    "### Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6b961b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e325c9e",
   "metadata": {},
   "source": [
    "### Test on novel examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "132c7dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5e6fc11cb64aba8f5b624f6823cf74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Batman context: The Justice League is made up of many heroes. Superman is an alien with super strength, x-ray vision, and the ability to fly. Batman uses his vast wealth to buy gadgets. Wonder Woman is an Amazon princess with an invisible jet, bulletproof bracelets, and a lasso of truth. The Flash is just really fast.\n",
      "Who is the richest member of the Justice League?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Who uses his wealth to buy gadgets?',\n",
       " 'Superman is an alien with super strength, x-ray vision, and the ability to fly. Wonder Woman is an Amazon princess with an invisible jet, bulletproof bracelets, and a lasso of truth?',\n",
       " 'Superman is an alien with super strength, x-ray vision, and the ability to fly. Wonder Woman is an Amazon princess with an invisible jet, bulletproof bracelets, and a lasso of truth.',\n",
       " 'Superman is an alien with super strength, x-ray vision, and the ability to fly, and Wonder Woman is an Amazon princess with an invisible jet, bulletproof bracelets, and a lasso of truth?',\n",
       " 'Superman is an alien with super strength, x-ray vision, and the ability to fly. Wonder Woman is an Amazon princess with an invisible jet, bulletproof bracelets, and a lasso of truth.',\n",
       " 'Superman is an alien with super strength, x-ray vision, and the ability to fly. Wonder Woman is an Amazon princess with an invisible jet, bulletproof bracelets, and a lasso of truth?',\n",
       " 'Superman is an alien with super strength, x-ray vision, and the ability to fly. Wonder Woman is an Amazon princess with an invisible jet, bulletproof bracelets, and a lasso of truth.',\n",
       " 'Superman is an alien with super strength, x-ray vision, and the ability to fly. Wonder Woman is an amazon princess with an invisible jet, bulletproof bracelets, and a lasso of truth.',\n",
       " 'Superman is an alien with super strength, x-ray vision, and the ability to fly. Wonder Woman is an amazon princess with an invisible jet, bulletproof bracelets, and a lasso of truth?',\n",
       " 'Superman is an alien with super strength, x-ray vision, and the ability to fly. Wonder Woman is an Amazon princess with an invisible jet, bulletproof bracelets, and lasso of truth.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize beam size and return sequences.\n",
    "args.beam_size = 10\n",
    "args.num_return_sequences = 10\n",
    "\n",
    "# Example A - Superhero Question\n",
    "novel_answer = \"Batman\"\n",
    "novel_context = \"The Justice League is made up of many heroes. Superman is an alien with super strength, x-ray vision, and the ability to fly. Batman uses his vast wealth to buy gadgets. Wonder Woman is an Amazon princess with an invisible jet, bulletproof bracelets, and a lasso of truth. The Flash is just really fast.\"\n",
    "novel_df = pd.DataFrame()\n",
    "novel_df['source'] = [\"answer: \" + novel_answer + \" context: \" + novel_context]\n",
    "novel_df['target'] = ['Who is the richest member of the Justice League?']\n",
    "novel_df['id'] = 0\n",
    "\n",
    "\n",
    "novel_example_output = Dataset.from_pandas(novel_df).map(\n",
    "    lambda batch: {'generated': beam_generate_sentences(\n",
    "        batch,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        args,\n",
    "        device='cuda:0')\n",
    "    },\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "novel_example_output\n",
    "\n",
    "# Prepare evaluation data\n",
    "novel_refs_list, novel_preds_list = prepare_eval(list(novel_example_output))\n",
    "\n",
    "# Show output\n",
    "novel_preds_list[0]['generated'].split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6adba935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee7e250aa1c400081ff90eb5faa58ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Stochastic gradient descent context: Stochastic gradient descent (often abbreviated SGD) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in high-dimensional optimization problems this reduces the very high computational burden, achieving faster iterations in trade for a lower convergence rate.\n",
      "What does SGD stand for?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What is an iterative method for optimizing an objective function with suitable smoothness properties?',\n",
       " 'What is an iterative method for optimizing an objective function?',\n",
       " 'What is an iterative method for optimizing an objective function with smoothness properties?',\n",
       " 'SGD is an iterative method for optimizing an objective function with suitable smoothness properties?',\n",
       " 'What is the iterative method for optimizing an objective function with suitable smoothness properties?',\n",
       " 'What is a iterative method for optimizing an objective function with suitable smoothness properties?',\n",
       " 'What is iterative method for optimizing an objective function with suitable smoothness properties?',\n",
       " 'What is an iterative method for optimizing an objective function with suitable smoothness properties called?',\n",
       " 'What is an iterative method of optimizing an objective function with suitable smoothness properties?',\n",
       " 'What is the iterative method for optimizing an objective function with smoothness properties?']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize beam size and return sequences.\n",
    "args.beam_size = 10\n",
    "args.num_return_sequences = 10\n",
    "\n",
    "# Example B - Machine Learning\n",
    "novel_answer = \"Stochastic gradient descent\"\n",
    "novel_context = \"Stochastic gradient descent (often abbreviated SGD) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in high-dimensional optimization problems this reduces the very high computational burden, achieving faster iterations in trade for a lower convergence rate.\"\n",
    "novel_df = pd.DataFrame()\n",
    "novel_df['source'] = [\"answer: \" + novel_answer + \" context: \" + novel_context]\n",
    "novel_df['target'] = ['What does SGD stand for?']\n",
    "novel_df['id'] = 0\n",
    "\n",
    "\n",
    "novel_example_output = Dataset.from_pandas(novel_df).map(\n",
    "    lambda batch: {'generated': beam_generate_sentences(\n",
    "        batch,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        args,\n",
    "        device='cuda:0')\n",
    "    },\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "novel_example_output\n",
    "\n",
    "# Prepare evaluation data\n",
    "novel_refs_list, novel_preds_list = prepare_eval(list(novel_example_output))\n",
    "\n",
    "# Show output\n",
    "novel_preds_list[0]['generated'].split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00d74c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3600170edfd4a2a9b7b081e35bc084d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 1066 context: William I, usually known as William the Conqueror and sometimes William the Bastard, was the first Norman king of England, reigning from 1066 until his death in 1087. A descendant of Rollo, he was Duke of Normandy from 1035 onward. By 1060, following a long struggle to establish his throne, his hold on Normandy was secure. In 1066, following the death of Edward the Confessor, William invaded England, leading an army of Normans to victory over the Anglo-Saxon forces of Harold Godwinson at the Battle of Hastings, and suppressed subsequent English revolts in what has become known as the Norman Conquest. The rest of his life was marked by struggles to consolidate his hold over England and his continental lands, and by difficulties with his eldest son, Robert Curthose.\n",
      "At which battle did William the Conqueror defeat Harold Godwinson?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['When did William the Conqueror reign?',\n",
       " 'When did William I reign?',\n",
       " 'In what year did William the Conqueror reign?',\n",
       " 'In what year did William I reign?',\n",
       " 'When did William I invade England?',\n",
       " 'When was William the Conqueror king of England?',\n",
       " 'In what year was William I the first Norman king of England?',\n",
       " 'When did William the Conqueror reign in England?',\n",
       " 'When did William I reign in England?',\n",
       " 'When was William the Conqueror born?']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize beam size and return sequences.\n",
    "args.beam_size = 10\n",
    "args.num_return_sequences = 10\n",
    "\n",
    "# Example C - World History\n",
    "novel_answer = \"1066\"\n",
    "novel_context = \"William I, usually known as William the Conqueror and sometimes William the Bastard, was the first Norman king of England, reigning from 1066 until his death in 1087. A descendant of Rollo, he was Duke of Normandy from 1035 onward. By 1060, following a long struggle to establish his throne, his hold on Normandy was secure. In 1066, following the death of Edward the Confessor, William invaded England, leading an army of Normans to victory over the Anglo-Saxon forces of Harold Godwinson at the Battle of Hastings, and suppressed subsequent English revolts in what has become known as the Norman Conquest. The rest of his life was marked by struggles to consolidate his hold over England and his continental lands, and by difficulties with his eldest son, Robert Curthose.\"\n",
    "novel_df = pd.DataFrame()\n",
    "novel_df['source'] = [\"answer: \" + novel_answer + \" context: \" + novel_context]\n",
    "novel_df['target'] = ['At which battle did William the Conqueror defeat Harold Godwinson?']\n",
    "novel_df['id'] = 0\n",
    "\n",
    "\n",
    "novel_example_output = Dataset.from_pandas(novel_df).map(\n",
    "    lambda batch: {'generated': beam_generate_sentences(\n",
    "        batch,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        args,\n",
    "        device='cuda:0')\n",
    "    },\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "novel_example_output\n",
    "\n",
    "# Prepare evaluation data\n",
    "novel_refs_list, novel_preds_list = prepare_eval(list(novel_example_output))\n",
    "\n",
    "# Show output\n",
    "novel_preds_list[0]['generated'].split('\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e296ca3",
   "metadata": {},
   "source": [
    "### Final predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50ae1d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/ec2-user/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5078daf8e7174b4585f93733218664f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29311c5725fe4d46a75345e50b2e2994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 21.127372392801167, 'counts': [29520, 13511, 7729, 4540], 'totals': [58232, 52947, 47662, 42377], 'precisions': [50.69377661766726, 25.51797080098967, 16.216272921824515, 10.713358661538098], 'bp': 0.9703448812087755, 'sys_len': 58232, 'ref_len': 59985}\n"
     ]
    }
   ],
   "source": [
    "# Make predictions (Beam)\n",
    "test_df = parse_data('test')\n",
    "\n",
    "test_output = Dataset.from_pandas(test_df).map(\n",
    "    lambda batch: {'generated': beam_generate_sentences(\n",
    "        batch,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        args,\n",
    "        device='cuda:0')\n",
    "    },\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "# prepare evaluation data\n",
    "ref_list, pred_list = prepare_eval(list(test_output))\n",
    "reference_dict = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": ref_list,\n",
    "}\n",
    "prediction_dict = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": pred_list,\n",
    "}\n",
    "\n",
    "# Calculate BLEU-4.\n",
    "metric = datasets.load_metric('sacrebleu')\n",
    "fin_targets = [reference_dict['values'][x]['target'] for x in range(0,len(reference_dict['values']))]\n",
    "fin_preds = [prediction_dict['values'][x]['generated'].split('\\t')[0] for x in range(0,len(prediction_dict['values']))]\n",
    "for model_predictions, gold_references in zip(fin_preds,fin_targets):\n",
    "    metric.add(predictions=model_predictions, references=gold_references)\n",
    "final_score = metric.compute()\n",
    "print(final_score)\n",
    "\n",
    "# Save pred/target lists.\n",
    "with open('FINAL_reference_dict_base256.json', 'w') as fp:\n",
    "    json.dump(reference_dict, fp)\n",
    "with open('FINAL_prediction_dict_base256.json', 'w') as fp:\n",
    "    json.dump(prediction_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ece87d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/ec2-user/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76b7479260142fc89dec197abceb526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f46d3ea2c147f08e16d41d13a7b73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5285 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 18.25875662855481, 'counts': [27420, 11684, 6420, 3649], 'totals': [53015, 47730, 42445, 37160], 'precisions': [51.721210978025084, 24.479363084014246, 15.125456473082814, 9.819698600645856], 'bp': 0.876803628158875, 'sys_len': 53015, 'ref_len': 59985}\n"
     ]
    }
   ],
   "source": [
    "# Make predictions (Nucleus)\n",
    "test_df = parse_data('test')\n",
    "args.top_p = 0.5\n",
    "args.top_k = 100\n",
    "\n",
    "test_output = Dataset.from_pandas(test_df).map(\n",
    "        lambda batch: {'generated': nucleus_search_sentences(\n",
    "            batch,\n",
    "            model,\n",
    "            tokenizer,\n",
    "            args,\n",
    "            device='cuda:0')\n",
    "        },\n",
    "        batched=True,\n",
    "        batch_size=1,\n",
    "    )\n",
    "\n",
    "# prepare evaluation data\n",
    "ref_list, pred_list = prepare_eval(list(test_output))\n",
    "reference_dict = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": ref_list,\n",
    "}\n",
    "prediction_dict = {\n",
    "    \"language\": \"en\",\n",
    "    \"values\": pred_list,\n",
    "}\n",
    "\n",
    "# Calculate BLEU-4.\n",
    "metric = datasets.load_metric('sacrebleu')\n",
    "fin_targets = [reference_dict['values'][x]['target'] for x in range(0,len(reference_dict['values']))]\n",
    "fin_preds = [prediction_dict['values'][x]['generated'].split('\\t')[0] for x in range(0,len(prediction_dict['values']))]\n",
    "for model_predictions, gold_references in zip(fin_preds,fin_targets):\n",
    "    metric.add(predictions=model_predictions, references=gold_references)\n",
    "final_score = metric.compute()\n",
    "print(final_score)\n",
    "\n",
    "# Save pred/target lists.\n",
    "with open('FINAL_NS_reference_dict_base256.json', 'w') as fp:\n",
    "    json.dump(reference_dict, fp)\n",
    "with open('FINAL_NS_prediction_dict_base256.json', 'w') as fp:\n",
    "    json.dump(prediction_dict, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
